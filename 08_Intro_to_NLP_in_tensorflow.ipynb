{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dots11/DavesProjects/blob/master/08_Intro_to_NLP_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDBNX5NZWcaa"
      },
      "source": [
        "## Introduction to NLP Fundamentals in TensorFlow\n",
        "NLP has the goal of deriving information out of natural language( could be sequence or speech)\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOchZi8nXNgd"
      },
      "source": [
        "## Check our GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS-6grvXW5t4",
        "outputId": "eef07534-9441-4a48-d08d-4ae0d048af3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct  2 11:59:44 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgLrayIwXWaZ"
      },
      "source": [
        "## Get helper functions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0QQ_6VQXVeI",
        "outputId": "decba0fa-42fa-4b00-8301-7c9457d3453d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-02 11:59:46--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-10-02 11:59:46 (57.7 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import a series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNwdgMClenBj"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text sample of Tweets labelled as disaster or not disaster).\n",
        "\n",
        "See the original source here: https://www.kaggle.com/competitions/nlp-getting-started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4wDwnIPCT_w"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxgjJO8Yei6D",
        "outputId": "bb857c82-4d91-43f5-cc54-a693144f9226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-02 11:59:50--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.157.128, 142.251.8.128, 74.125.23.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.157.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "nlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2022-10-02 11:59:50 (113 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4CxM5TjXQ8Z"
      },
      "outputs": [],
      "source": [
        "# Unzip data\n",
        "\n",
        "unzip_data(\"nlp_getting_started.zip\")\n",
        "\n",
        "# we get sample_submission, test and train.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6CBvrnpi7Bu"
      },
      "source": [
        "## Visualizing a text data\n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way to do so is to use Python: https://realpython.com/read-write-files-python/\n",
        "\n",
        "But ideally to get visual right away.\n",
        "\n",
        "So another way to do this is to use pandas..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ETlv0JwRiabn",
        "outputId": "dc754f3c-89d3-4940-803d-59850c800b06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf7022f9-a1fa-4b86-a782-303c69121fa3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf7022f9-a1fa-4b86-a782-303c69121fa3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf7022f9-a1fa-4b86-a782-303c69121fa3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf7022f9-a1fa-4b86-a782-303c69121fa3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hpgSbxJWDXWe",
        "outputId": "13bd65fc-047e-41f9-cf1d-f11b34743674"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Forest fire near La Ronge Sask. Canada'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_df[\"text\"][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "NRmtp-LPJJ95",
        "outputId": "50880a10-a943-4b67-b366-c15361422387"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id       keyword                        location  \\\n",
              "2644   3796   destruction                             NaN   \n",
              "2227   3185        deluge                             NaN   \n",
              "5448   7769        police                              UK   \n",
              "132     191    aftershock                             NaN   \n",
              "6845   9810        trauma           Montgomery County, MD   \n",
              "...     ...           ...                             ...   \n",
              "5226   7470  obliteration                         Merica!   \n",
              "5390   7691         panic                             NaN   \n",
              "860    1242         blood                             NaN   \n",
              "7603  10862           NaN                             NaN   \n",
              "7270  10409     whirlwind  Stamford & Cork (& Shropshire)   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  \n",
              "...                                                 ...     ...  \n",
              "5226  @Eganator2000 There aren't many Obliteration s...       0  \n",
              "5390  just had a panic attack bc I don't have enough...       0  \n",
              "860   Omron HEM-712C Automatic Blood Pressure Monito...       0  \n",
              "7603  Officials say a quarantine is in place at an A...       1  \n",
              "7270  I moved to England five years ago today. What ...       1  \n",
              "\n",
              "[7613 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01d86e19-e35e-46cd-a621-1eeaf18f5cb3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5226</th>\n",
              "      <td>7470</td>\n",
              "      <td>obliteration</td>\n",
              "      <td>Merica!</td>\n",
              "      <td>@Eganator2000 There aren't many Obliteration s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>7691</td>\n",
              "      <td>panic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>just had a panic attack bc I don't have enough...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>1242</td>\n",
              "      <td>blood</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Omron HEM-712C Automatic Blood Pressure Monito...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7603</th>\n",
              "      <td>10862</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Officials say a quarantine is in place at an A...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>10409</td>\n",
              "      <td>whirlwind</td>\n",
              "      <td>Stamford &amp; Cork (&amp; Shropshire)</td>\n",
              "      <td>I moved to England five years ago today. What ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01d86e19-e35e-46cd-a621-1eeaf18f5cb3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01d86e19-e35e-46cd-a621-1eeaf18f5cb3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01d86e19-e35e-46cd-a621-1eeaf18f5cb3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42) # 'frac' what % should we shuffle? 1 represents 100%, 'random_state' sets shuffle in particular order e.g. '42'\n",
        "train_df_shuffled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oI55kgjJfe4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "hWtJqSxaKCmK",
        "outputId": "4519dc23-18d6-45ff-812a-6083dce2f897"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DT @georgegalloway: RT @Galloway4Mayor: \\x89ÛÏThe CoL police can catch a pickpocket in Liverpool Stree... http://t.co/vXIn1gOq4Q'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_df[\"text\"][5448]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tR6XB8YvKFM6",
        "outputId": "31497182-653e-44bd-e192-616f640fd96b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b858856-b355-40a0-87e8-2a6b4a212346\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b858856-b355-40a0-87e8-2a6b4a212346')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b858856-b355-40a0-87e8-2a6b4a212346 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b858856-b355-40a0-87e8-2a6b4a212346');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# What does the test dataframe look like?\n",
        "test_df.head()\n",
        "\n",
        "# same as train dataframe except no targets column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZoN-EXOKnM4",
        "outputId": "2a2a4979-306f-49c0-a713-5eb9351d87e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# How many examples are there in each class?\n",
        "train_df.target.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiJwnw0xMU1j"
      },
      "source": [
        "Looks pretty balanced, though if your dataset is imbalanced, refer to this link on tensorflow: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
        "This will recommend a few changes to resolve the imbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG0UuFaIMSMa",
        "outputId": "fe7dda92-55fc-4d9c-97f3-7d879b179b97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# How many total samples?\n",
        "len(train_df), len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hslN-GQRNStK",
        "outputId": "b7be601d-e2b0-49f6-f027-ce360690c2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target:\n",
            "1\n",
            " (real_disaster)\n",
            "Text:\n",
            "#SigAlert: North &amp; Southbound 133 closed btwn 5 fwy and Irvine Blvd due to truck fire. CHP is detouring traffic.\n",
            "\n",
            "---\n",
            "\n",
            "Target:\n",
            "0\n",
            " (not a real disaster)\n",
            "Text:\n",
            "Summer #summervibes #california #puppy #pitmix #rescued #brixton #banksy #happy #mybabies https://t.co/7VoVkTXsPo\n",
            "\n",
            "---\n",
            "\n",
            "Target:\n",
            "1\n",
            " (real_disaster)\n",
            "Text:\n",
            "There's a weird siren going off here...I hope Hunterston isn't in the process of blowing itself to smithereens...\n",
            "\n",
            "---\n",
            "\n",
            "Target:\n",
            "0\n",
            " (not a real disaster)\n",
            "Text:\n",
            "@_RedDevil4Life_ @ManUtd destroyed!??\n",
            "\n",
            "---\n",
            "\n",
            "Target:\n",
            "1\n",
            " (real_disaster)\n",
            "Text:\n",
            "the sunset boys wreck my bed   original 1979 usa gimp label  vinyl 7' 45  newave http://t.co/X0QLgwoyMT http://t.co/hQNx8qMeG3\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's visualize some random training samples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # Create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index + 5].itertuples(): # returns tuples of ('text', 'target')\n",
        "  _, text, target = row # \"_\" gets rid of the index.\n",
        "  print(f\"Target:\\n{target}\\n\", \"(real_disaster)\" if target > 0 else \"(not a real disaster)\") # if target = \"1\" it is a \"real disaster\", else it is \"not a disaster\"\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VI8gYzHaM55"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3XaFY7oT_Ui"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOJ1CM0cdTId"
      },
      "outputs": [],
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(), # expects train_test_split data to be in the form of numpy arrays\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size = 0.1, # use 10% of training data for validation split\n",
        "                                                                            random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPNSYCkfIYM6",
        "outputId": "7313b325-d146-4023-83c3-e18a1759ddf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edmFKXHRR_Fs",
        "outputId": "6a0fc2eb-0f14-4423-c3de-de34652d0d15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(train_df_shuffled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxz6tNd0SS0s",
        "outputId": "64564bf6-2fc8-4d61-efb4-16c3deb34e1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqpj_Qs2alxl"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealling with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
        "\n",
        "There are a few ways to do this:\n",
        "\n",
        "* Tokenization - direct mapping of token (a token could be a word or a character) to a number.\n",
        "\n",
        "* Embedding - create a matrix of feature vectors for each token (the size of the feature vector can be defined and this embedding can be learned)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CW8tfJTeYwq"
      },
      "source": [
        "### Text Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOPIspTlSm74",
        "outputId": "551b6593-c476-45f9-8ab2-3daa4f7fa540"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_sentences[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDvVx2o-eeaP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens= 1000, # how many words in the vocabulary (automtically add <OOV> \"out of vocabulary\")\n",
        "                                    standardize = \"lower_and_strip_punctuation\",\n",
        "                                    split = \"whitespace\",\n",
        "                                    ngrams = None, # create groups of n-words?, if set to \"None\", treats every token on their own rather grouping together\n",
        "                                    output_mode = \"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length = None, # How long do you want your sequence to be? If set to 'None' Automatically pads each sequence to the longest sequence e.g. smaller sequences get padded with zeroes at the end until matches longest sequence.\n",
        "                                    pad_to_max_tokens = True) # 'True' allows to pad zeros at the end of each token to match the longest token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNnMem1o3BdJ",
        "outputId": "07879b93-a975-4862-ca0e-be1299d9ebb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(train_sentences[0].split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "493kzRIqeqOv",
        "outputId": "6103b5fa-9d8a-453a-df46-71469285dc02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Find the averagae number of tokens (words) in our training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QWdbYRg3f77"
      },
      "outputs": [],
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does a model see?) e.g. if tweet 30 words long, it will only see first 15\n",
        "\n",
        "# Resetting this to set specified parameters needed\n",
        "text_vectorizer = TextVectorization(max_tokens = max_vocab_length,\n",
        "                                    output_mode = \"int\",\n",
        "                                    output_sequence_length = max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzuwn1xm6mY8"
      },
      "outputs": [],
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMVZTZmupu0g",
        "outputId": "6b9b6bf1-58d3-4515-8859-87ddc7476573"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb0IfY2UpxAQ",
        "outputId": "18d6f8ca-4dec-4a72-bb3a-3c8e99ef9600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "That horrible moment when u open up the dryer and it looks like a snowy blizzard cuz u left a piece of paper in your jeans pocket ??      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  16,  395, 1005,   45,  142, 1497,   27,    2, 5766,    7,   15,\n",
              "         287,   25,    3, 8339]])>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7yMYawlq1Do",
        "outputId": "0511e2cf-8765-480e-ad94-fe7fd8040630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ],
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all the unique words in our training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words: {top_5_words}\")\n",
        "print(f\"5 least common words: {bottom_5_words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LwP1E5XIkI_"
      },
      "outputs": [],
      "source": [
        "# '[UNK]' is a word outside the top \"10,000\" (or other value set as max_vocab_length)\n",
        "# As '[UNK]' is a top 5 word, as this depends on the no. of training sentences we have. We can change the vocab size e.g. 20,000 to increase capacity to memorize unique words, therefore making '[UNK]' least common."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn4lM2_oJJcl",
        "outputId": "012593fa-0fab-4c58-ecb6-e648dc387faa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       ...,\n",
              "       'Near them on the sand half sunk a shattered visage lies... http://t.co/0kCCG1BT06',\n",
              "       \"kesabaran membuahkan hasil indah pada saat tepat! life isn't about waiting for the storm to pass it's about learning to dance in the rain.\",\n",
              "       \"@ScottDPierce @billharris_tv @HarrisGle @Beezersun I'm forfeiting this years fantasy football pool out of fear I may win n get my ass kicked\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "train_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oojqJkfrKdiT"
      },
      "source": [
        "### So we created a text vectorizer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xYe1xM-KmRU"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "To make our embedding, we are going to use TensorFlow's embedding layer\n",
        "\n",
        "The parameters we care most about for our embedding layer:\n",
        "\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedded vector, for example, a value of 100 would mean each token gets represented by a vector 100 long.\n",
        "* `input_length` = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3BuCOw3P3jx",
        "outputId": "f085f0c1-cfdc-4246-bf75-56f19875642e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7fee1457d150>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length, # set input shape\n",
        "                             output_dim = 128, # output shape, divisible by '8'\n",
        "                             embeddings_initializer = \"uniform\", #default initialize randomally\n",
        "                             input_length = max_length, # how long is each input\n",
        "                             name = \"embedding_1\"\n",
        "                             )\n",
        "embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4iF3J8EvQ2u",
        "outputId": "7f7cc018-3aa4-4b98-ca40-02472c7e1991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "Experts in France begin examining airplane debris found on Reunion Island http://t.co/LsMx2vwr3J French air accident experts on WednesdayÛ_      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.01936599, -0.01923897,  0.03844601, ...,  0.0098206 ,\n",
              "          0.01055583, -0.03042114],\n",
              "        [-0.01981794, -0.03104698, -0.02752581, ...,  0.00884819,\n",
              "          0.03085944,  0.00997077],\n",
              "        [-0.04287907,  0.03893036, -0.03464825, ...,  0.00242417,\n",
              "          0.00551404, -0.00316463],\n",
              "        ...,\n",
              "        [ 0.01437361, -0.03186138,  0.03752223, ..., -0.04052367,\n",
              "         -0.01712488,  0.02386818],\n",
              "        [ 0.04244764, -0.01196362,  0.01855623, ..., -0.04782499,\n",
              "          0.04605179,  0.04177728],\n",
              "        [ 0.01035818,  0.01249452, -0.02984692, ..., -0.00978519,\n",
              "         -0.02944517,  0.04714574]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2fAfLWpPj7_",
        "outputId": "ad34a3f9-6489-4b91-9c76-cada2d7cf9f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.01936599, -0.01923897,  0.03844601,  0.0106287 , -0.00686228,\n",
              "         0.01971902,  0.00276736,  0.03402043,  0.0060725 ,  0.03584895,\n",
              "        -0.02960426, -0.04037102,  0.041316  , -0.04000203, -0.0477327 ,\n",
              "         0.00256578,  0.01953074, -0.0432955 ,  0.04921087, -0.00181349,\n",
              "         0.00884215,  0.02408506,  0.01837048,  0.037956  , -0.02218289,\n",
              "        -0.01323148, -0.01814038,  0.04723588,  0.04060651, -0.00328568,\n",
              "         0.01737184,  0.04075059, -0.03089582,  0.02638311,  0.03045132,\n",
              "        -0.03895633, -0.0346444 ,  0.04246453,  0.02144564, -0.00613786,\n",
              "        -0.04070634, -0.03222015, -0.01610126,  0.01424395,  0.03685733,\n",
              "         0.025098  ,  0.00697974,  0.01708604, -0.03979281,  0.01401288,\n",
              "         0.04286054, -0.02194338,  0.02987895,  0.02347634,  0.01030006,\n",
              "         0.01840207, -0.03490187,  0.01339832,  0.02839849,  0.04494463,\n",
              "         0.01193274, -0.02866137,  0.00750718, -0.03039608,  0.01822821,\n",
              "         0.04116798, -0.00462797, -0.03753581, -0.00072479, -0.01073425,\n",
              "        -0.03716733, -0.02386049, -0.01328304, -0.00504768,  0.03158971,\n",
              "        -0.02583535,  0.01145048,  0.01095501, -0.02520143, -0.0077297 ,\n",
              "         0.03106996,  0.01817011, -0.04995202, -0.01201762,  0.04868395,\n",
              "         0.04500696,  0.02965376, -0.0168284 ,  0.0108133 ,  0.01599157,\n",
              "        -0.00714601,  0.03801842,  0.0274795 , -0.04718772,  0.0181612 ,\n",
              "        -0.04775946,  0.01028984, -0.04128361,  0.04431051, -0.0477612 ,\n",
              "        -0.02310309,  0.04367479, -0.02510775,  0.01759647,  0.01230911,\n",
              "        -0.00366605,  0.00695801, -0.04565619,  0.02695585, -0.03523199,\n",
              "         0.0049134 ,  0.03096627, -0.00423626,  0.03282446,  0.04803354,\n",
              "        -0.00408828,  0.01563312,  0.0294806 ,  0.01813782, -0.04323542,\n",
              "        -0.02613436, -0.01704072, -0.0133999 , -0.04243746, -0.00364914,\n",
              "         0.0098206 ,  0.01055583, -0.03042114], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'Experts in France begin examining airplane debris found on Reunion Island http://t.co/LsMx2vwr3J French air accident experts on Wednesday\\x89Û_')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence # indexing to the very first token of the shape (1,15,128)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w5NutlXPdit"
      },
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "\n",
        "Now we've got a way to turn our text sequences into numbers, it's time to start building a series of modelling experiments.\n",
        "\n",
        "We'll start with a baseline and move on from there.\n",
        "\n",
        "* Model 0: Nave Bayes (baseline), from the Sklearn ML map: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html?highlight=choosing+right+estimator \n",
        "* Model 1: Feed-forward neural network (dense model)\n",
        "* Model 2: LSTM model (RNN)\n",
        "* Model 3: GRU model (RNN)\n",
        "* Model 4: Bidirectional-LSTM model (RNN)\n",
        "* Model 5: 1D Convolutional Neural Network (CNN)\n",
        "* Model 6: TensorFlow Hub Pretrained Feature Extractor (using transfer learning for NLP)\n",
        "* Model 7: Same as model 6 with 10% of training data.\n",
        "\n",
        "How are we going to approach all of these?\n",
        "\n",
        "Use the standard steps in modelling with TensorFlow\n",
        "\n",
        "* Create the model\n",
        "* Build the model\n",
        "* Fit the model\n",
        "* Evaluate our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQCLm8eXT0F6"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "As for all machine learning modelling experiments, it's important to  create a baseline model so you've got a benchmark for future experiments to build upon.\n",
        "\n",
        "To create our baseline, we'll use Sklearn's Multinomial Naive Bayes using the TF-IDF formula to convert our words to numbers.\n",
        "\n",
        "**Note:** it's common practice to use non-DL algorithms as a baseline because of their speed and then later using DL to see if you can improve upon them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXAwfYBZw8NV",
        "outputId": "778539af-46f6-471d-c594-9009c791248e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline (like the sequential)\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTtgve7L3lvG",
        "outputId": "81068bf9-83e1-4e6d-b745-31f5f58cccd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels) # in keras its 'evaluate', and sklearn its 'score'\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKDc0hRY4Y4X",
        "outputId": "e4c8eed8-6df0-4eb3-be49-ee0178df027f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "train_df.target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvPw82qDIQRg",
        "outputId": "165e6a01-fdd9-4441-b1f2-ac6399056a1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences) # same as tensorflow there is a predict method in sklearn\n",
        "baseline_preds[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bdWzDEaIp4e",
        "outputId": "e3cbab04-aa24-497a-ae2d-179b8b7421c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "train_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwuj5pE3IpUf"
      },
      "source": [
        "### Create an evaluation funciton for our model experiments\n",
        "\n",
        "We could evaluate our model's predictions with different metrics every time, however, this will be cumbersome and could easily be fixed with a function\n",
        "\n",
        "Let's create one to compare our model's predictions with the truth labels using the following metrics:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n",
        "\n",
        "For a deep overview of many different evaluation methods please see the Scikit learn documentation https://scikit-learn.org/stable/modules/model_evaluation.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brk4jczOJ0es"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1-score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average = \"weighted\") #\"_\" represents a blank variable we don't want to use\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1\": model_f1}\n",
        "  return model_results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHK31PXXuLEN",
        "outputId": "45cfad87-ed83-45fd-c857-ea4f814ad124"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdIx9MP8wKAU"
      },
      "outputs": [],
      "source": [
        "from helper_functions import calculate_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckc9gLtM20X8"
      },
      "source": [
        "### Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqowWa6N1CQM"
      },
      "outputs": [],
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CswZKqqPBX4K"
      },
      "outputs": [],
      "source": [
        "# Build model with the Functional API # 'Functional API' is more customizable than the 'Sequential API'\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape =(1, ), dtype=tf.string) # inputs are 1-dimensional strings, and shape is '(1, )' to see 1 sequence at a time.\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numerized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x) # Lower the dimensionality of the embedding (try running the model without this layer and see what happens). # Condenses the feature vector for each token to one vector.\n",
        "#x = layers.GlobalMaxPool1D()(x) # yielded similar results to the layer above\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x) # '1' output because we are binary classifying it to be either 'disaster' or 'no disaster'. We want binary outputs so we use sigmoid activation \n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PekVxUykH0FS",
        "outputId": "2401d058-b76d-4f6b-a0d8-f21bbf739712"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7fee1457d150>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Check embedding\n",
        "embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si7DdcGuCNPK",
        "outputId": "8727171b-4a2d-4acb-d0d8-aa0cbab88536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1.summary()\n",
        "# in the summary, we pass one input through to the input layer as a string sequence at a time, then each inputted sequence gets text vectorized to be 15 integers long.\n",
        "# The vectorized data then gets embedded, adding a dimension to the end e.g. 128 resulting in many parameters. Each of the 15 tokens gets represented as a 128 long feature vector \n",
        "# Then each feature vector is then passed through the dense layer and outputs with the size of '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STbpr6rRKYjo"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model_1.compile(loss = \"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epp3dBElOCzX",
        "outputId": "661c701e-5e86-49b6-f413-008f0dc4cfd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20221002-115956\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 6ms/step - loss: 0.6117 - accuracy: 0.6920 - val_loss: 0.5351 - val_accuracy: 0.7625\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.4421 - accuracy: 0.8189 - val_loss: 0.4724 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.3478 - accuracy: 0.8610 - val_loss: 0.4551 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.2847 - accuracy: 0.8897 - val_loss: 0.4663 - val_accuracy: 0.7887\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.2382 - accuracy: 0.9110 - val_loss: 0.4772 - val_accuracy: 0.7795\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data = (val_sentences, val_labels), # combining both into a 'tuple'\n",
        "                              callbacks=[create_tensorboard_callback(dir_name = SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_1_dense\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD7EFg6yOmEI",
        "outputId": "386de7fc-7347-469a-9ceb-e5a3e676faee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "baseline_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISktXaYATltX",
        "outputId": "ef59bb49-4198-401c-96e8-8e7c7ff36fbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7795\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47717714309692383, 0.7795275449752808]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRl5rvqzT00o",
        "outputId": "85714ac1-1724-4c52-8c63-bf69d986d2c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape # if multip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRhCSKP1UsM4",
        "outputId": "9687e18d-7a1a-40c9-cec2-b36d68e426b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.40661392], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Checking the first prediction (looks all good!)\n",
        "model_1_pred_probs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFD6dS-vW1LJ",
        "outputId": "4e88ce4b-fb70-4eca-e08f-fd17cece6855"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40661392],\n",
              "       [0.83657897],\n",
              "       [0.99749917],\n",
              "       [0.12710689],\n",
              "       [0.10593968],\n",
              "       [0.94930077],\n",
              "       [0.9286818 ],\n",
              "       [0.99326754],\n",
              "       [0.96876615],\n",
              "       [0.28698525],\n",
              "       [0.13499144],\n",
              "       [0.7138778 ],\n",
              "       [0.06523987],\n",
              "       [0.18799509],\n",
              "       [0.00486957],\n",
              "       [0.16077486],\n",
              "       [0.03537278],\n",
              "       [0.09027416],\n",
              "       [0.29134107],\n",
              "       [0.59382504],\n",
              "       [0.914466  ],\n",
              "       [0.04645042],\n",
              "       [0.4916934 ],\n",
              "       [0.09402687],\n",
              "       [0.9613288 ],\n",
              "       [0.99880695],\n",
              "       [0.03580347],\n",
              "       [0.08413623],\n",
              "       [0.03090259],\n",
              "       [0.2131401 ],\n",
              "       [0.60610366],\n",
              "       [0.2716794 ],\n",
              "       [0.518601  ],\n",
              "       [0.21170762],\n",
              "       [0.55463344],\n",
              "       [0.0656057 ],\n",
              "       [0.99497664],\n",
              "       [0.17106676],\n",
              "       [0.03676022],\n",
              "       [0.99849   ],\n",
              "       [0.21371281],\n",
              "       [0.02380392],\n",
              "       [0.3466438 ],\n",
              "       [0.07981589],\n",
              "       [0.69101334],\n",
              "       [0.98610663],\n",
              "       [0.32506046],\n",
              "       [0.9263247 ],\n",
              "       [0.23375233],\n",
              "       [0.62640405],\n",
              "       [0.07935622],\n",
              "       [0.5981969 ],\n",
              "       [0.4984128 ],\n",
              "       [0.03686649],\n",
              "       [0.12587054],\n",
              "       [0.04349291],\n",
              "       [0.2813687 ],\n",
              "       [0.96032435],\n",
              "       [0.13382508],\n",
              "       [0.00224403],\n",
              "       [0.15496704],\n",
              "       [0.96273   ],\n",
              "       [0.9339252 ],\n",
              "       [0.19348593],\n",
              "       [0.9366577 ],\n",
              "       [0.97923833],\n",
              "       [0.7681002 ],\n",
              "       [0.3787578 ],\n",
              "       [0.12244906],\n",
              "       [0.16021113],\n",
              "       [0.0681555 ],\n",
              "       [0.0354902 ],\n",
              "       [0.9445937 ],\n",
              "       [0.15622401],\n",
              "       [0.14242058],\n",
              "       [0.45937046],\n",
              "       [0.43106166],\n",
              "       [0.85533565],\n",
              "       [0.297574  ],\n",
              "       [0.6730048 ],\n",
              "       [0.4878029 ],\n",
              "       [0.26246434],\n",
              "       [0.9964593 ],\n",
              "       [0.11900015],\n",
              "       [0.18688467],\n",
              "       [0.10048853],\n",
              "       [0.02143593],\n",
              "       [0.10515022],\n",
              "       [0.6657702 ],\n",
              "       [0.9020585 ],\n",
              "       [0.99210054],\n",
              "       [0.01306721],\n",
              "       [0.6128964 ],\n",
              "       [0.0332685 ],\n",
              "       [0.9856346 ],\n",
              "       [0.8296867 ],\n",
              "       [0.86166155],\n",
              "       [0.9766975 ],\n",
              "       [0.8921829 ],\n",
              "       [0.964874  ],\n",
              "       [0.99932015],\n",
              "       [0.20320393],\n",
              "       [0.01635714],\n",
              "       [0.9342916 ],\n",
              "       [0.91071177],\n",
              "       [0.07908645],\n",
              "       [0.89757407],\n",
              "       [0.9798253 ],\n",
              "       [0.07715987],\n",
              "       [0.49986228],\n",
              "       [0.73871243],\n",
              "       [0.04242469],\n",
              "       [0.27582267],\n",
              "       [0.19173796],\n",
              "       [0.16751193],\n",
              "       [0.5561252 ],\n",
              "       [0.51542467],\n",
              "       [0.75451845],\n",
              "       [0.76595265],\n",
              "       [0.09394265],\n",
              "       [0.999716  ],\n",
              "       [0.10104626],\n",
              "       [0.13775505],\n",
              "       [0.83525693],\n",
              "       [0.43694484],\n",
              "       [0.28449103],\n",
              "       [0.8325919 ],\n",
              "       [0.00973683],\n",
              "       [0.0831379 ],\n",
              "       [0.8217269 ],\n",
              "       [0.10944122],\n",
              "       [0.999716  ],\n",
              "       [0.99984753],\n",
              "       [0.99880695],\n",
              "       [0.9871563 ],\n",
              "       [0.08773623],\n",
              "       [0.97366714],\n",
              "       [0.18976995],\n",
              "       [0.31933197],\n",
              "       [0.08753407],\n",
              "       [0.996876  ],\n",
              "       [0.350219  ],\n",
              "       [0.18799509],\n",
              "       [0.9635004 ],\n",
              "       [0.29419947],\n",
              "       [0.6671292 ],\n",
              "       [0.04883094],\n",
              "       [0.0086801 ],\n",
              "       [0.29385465],\n",
              "       [0.98065954],\n",
              "       [0.3143495 ],\n",
              "       [0.0728455 ],\n",
              "       [0.48900855],\n",
              "       [0.22504717],\n",
              "       [0.24491462],\n",
              "       [0.9932741 ],\n",
              "       [0.81875104],\n",
              "       [0.5376998 ],\n",
              "       [0.98889077],\n",
              "       [0.02269083],\n",
              "       [0.9783529 ],\n",
              "       [0.06456253],\n",
              "       [0.30316788],\n",
              "       [0.99242157],\n",
              "       [0.27441674],\n",
              "       [0.08753581],\n",
              "       [0.99877447],\n",
              "       [0.31179515],\n",
              "       [0.98422456],\n",
              "       [0.23690283],\n",
              "       [0.9940772 ],\n",
              "       [0.8638121 ],\n",
              "       [0.8563843 ],\n",
              "       [0.03944845],\n",
              "       [0.9983822 ],\n",
              "       [0.06853781],\n",
              "       [0.42248955],\n",
              "       [0.48931095],\n",
              "       [0.75882643],\n",
              "       [0.9944676 ],\n",
              "       [0.01697654],\n",
              "       [0.8667152 ],\n",
              "       [0.812338  ],\n",
              "       [0.97093374],\n",
              "       [0.9783433 ],\n",
              "       [0.43134695],\n",
              "       [0.1086783 ],\n",
              "       [0.9995647 ],\n",
              "       [0.0143374 ],\n",
              "       [0.03298344],\n",
              "       [0.1414805 ],\n",
              "       [0.9368214 ],\n",
              "       [0.11125538],\n",
              "       [0.2921931 ],\n",
              "       [0.01895345],\n",
              "       [0.11621229],\n",
              "       [0.05386295],\n",
              "       [0.23691669],\n",
              "       [0.7962005 ],\n",
              "       [0.09274045],\n",
              "       [0.2739597 ],\n",
              "       [0.88814634],\n",
              "       [0.9750473 ],\n",
              "       [0.37955838],\n",
              "       [0.1343496 ],\n",
              "       [0.9998349 ],\n",
              "       [0.55932194],\n",
              "       [0.940852  ],\n",
              "       [0.64770776],\n",
              "       [0.86871004],\n",
              "       [0.37561294],\n",
              "       [0.98574346],\n",
              "       [0.0213738 ],\n",
              "       [0.2003012 ],\n",
              "       [0.00855375],\n",
              "       [0.00561064],\n",
              "       [0.9596979 ],\n",
              "       [0.8523894 ],\n",
              "       [0.9070864 ],\n",
              "       [0.1803663 ],\n",
              "       [0.7250409 ],\n",
              "       [0.10275662],\n",
              "       [0.02609156],\n",
              "       [0.20933588],\n",
              "       [0.9812259 ],\n",
              "       [0.23364992],\n",
              "       [0.551468  ],\n",
              "       [0.9954834 ],\n",
              "       [0.65496796],\n",
              "       [0.6590571 ],\n",
              "       [0.11459702],\n",
              "       [0.2200897 ],\n",
              "       [0.83424354],\n",
              "       [0.2556785 ],\n",
              "       [0.5599321 ],\n",
              "       [0.1631145 ],\n",
              "       [0.58483684],\n",
              "       [0.3764639 ],\n",
              "       [0.20824382],\n",
              "       [0.08294186],\n",
              "       [0.42183638],\n",
              "       [0.32086632],\n",
              "       [0.99987495],\n",
              "       [0.9872028 ],\n",
              "       [0.08627025],\n",
              "       [0.02665018],\n",
              "       [0.8726518 ],\n",
              "       [0.11974411],\n",
              "       [0.09380496],\n",
              "       [0.47497115],\n",
              "       [0.04816367],\n",
              "       [0.595953  ],\n",
              "       [0.00111701],\n",
              "       [0.44342425],\n",
              "       [0.9372977 ],\n",
              "       [0.23473704],\n",
              "       [0.9772679 ],\n",
              "       [0.99903667],\n",
              "       [0.29943022],\n",
              "       [0.18320188],\n",
              "       [0.38408497],\n",
              "       [0.03642659],\n",
              "       [0.00491568],\n",
              "       [0.987265  ],\n",
              "       [0.97288007],\n",
              "       [0.73824716],\n",
              "       [0.9556923 ],\n",
              "       [0.05964254],\n",
              "       [0.19483283],\n",
              "       [0.01077105],\n",
              "       [0.19297926],\n",
              "       [0.044013  ],\n",
              "       [0.96315455],\n",
              "       [0.10209485],\n",
              "       [0.00975915],\n",
              "       [0.97454005],\n",
              "       [0.01244579],\n",
              "       [0.12460032],\n",
              "       [0.98756194],\n",
              "       [0.03973949],\n",
              "       [0.0829929 ],\n",
              "       [0.00567212],\n",
              "       [0.9728932 ],\n",
              "       [0.6377033 ],\n",
              "       [0.7771589 ],\n",
              "       [0.7404664 ],\n",
              "       [0.6470645 ],\n",
              "       [0.06901827],\n",
              "       [0.9421551 ],\n",
              "       [0.03314559],\n",
              "       [0.77983433],\n",
              "       [0.42543766],\n",
              "       [0.4146222 ],\n",
              "       [0.43724412],\n",
              "       [0.23747721],\n",
              "       [0.7626484 ],\n",
              "       [0.27989894],\n",
              "       [0.7368964 ],\n",
              "       [0.13808687],\n",
              "       [0.84860927],\n",
              "       [0.05273551],\n",
              "       [0.08971632],\n",
              "       [0.31277755],\n",
              "       [0.98692304],\n",
              "       [0.1967543 ],\n",
              "       [0.09876312],\n",
              "       [0.29702604],\n",
              "       [0.2508308 ],\n",
              "       [0.12674159],\n",
              "       [0.0341053 ],\n",
              "       [0.03761016],\n",
              "       [0.9854283 ],\n",
              "       [0.3766119 ],\n",
              "       [0.25515977],\n",
              "       [0.9997702 ],\n",
              "       [0.05422549],\n",
              "       [0.6602642 ],\n",
              "       [0.27048516],\n",
              "       [0.05159765],\n",
              "       [0.17033044],\n",
              "       [0.20156105],\n",
              "       [0.1134587 ],\n",
              "       [0.939885  ],\n",
              "       [0.27342477],\n",
              "       [0.98621964],\n",
              "       [0.11258334],\n",
              "       [0.02088342],\n",
              "       [0.9959558 ],\n",
              "       [0.02327418],\n",
              "       [0.99706143],\n",
              "       [0.16859668],\n",
              "       [0.03545259],\n",
              "       [0.96664065],\n",
              "       [0.05198674],\n",
              "       [0.03598996],\n",
              "       [0.9815092 ],\n",
              "       [0.00608761],\n",
              "       [0.22090036],\n",
              "       [0.7859296 ],\n",
              "       [0.9377582 ],\n",
              "       [0.00497556],\n",
              "       [0.20671783],\n",
              "       [0.982179  ],\n",
              "       [0.96881986],\n",
              "       [0.8135796 ],\n",
              "       [0.46867597],\n",
              "       [0.62489307],\n",
              "       [0.44880304],\n",
              "       [0.0596226 ],\n",
              "       [0.12357899],\n",
              "       [0.10970708],\n",
              "       [0.7480166 ],\n",
              "       [0.03955457],\n",
              "       [0.44938266],\n",
              "       [0.45560962],\n",
              "       [0.01426898],\n",
              "       [0.9676989 ],\n",
              "       [0.99880695],\n",
              "       [0.99549943],\n",
              "       [0.03603981],\n",
              "       [0.38271546],\n",
              "       [0.14275447],\n",
              "       [0.41767088],\n",
              "       [0.7756841 ],\n",
              "       [0.22926024],\n",
              "       [0.02048648],\n",
              "       [0.08274872],\n",
              "       [0.04658068],\n",
              "       [0.62330794],\n",
              "       [0.00909316],\n",
              "       [0.24244733],\n",
              "       [0.03953175],\n",
              "       [0.43168926],\n",
              "       [0.5018171 ],\n",
              "       [0.3731342 ],\n",
              "       [0.1962981 ],\n",
              "       [0.06642348],\n",
              "       [0.3225758 ],\n",
              "       [0.0961208 ],\n",
              "       [0.99668044],\n",
              "       [0.9198699 ],\n",
              "       [0.47628793],\n",
              "       [0.6317868 ],\n",
              "       [0.02327346],\n",
              "       [0.5465828 ],\n",
              "       [0.99060494],\n",
              "       [0.7228712 ],\n",
              "       [0.17858276],\n",
              "       [0.9846431 ],\n",
              "       [0.2398329 ],\n",
              "       [0.93774277],\n",
              "       [0.30747825],\n",
              "       [0.02780193],\n",
              "       [0.5911036 ],\n",
              "       [0.445724  ],\n",
              "       [0.99698025],\n",
              "       [0.11461633],\n",
              "       [0.04789565],\n",
              "       [0.09658155],\n",
              "       [0.22926024],\n",
              "       [0.999064  ],\n",
              "       [0.02760314],\n",
              "       [0.6606303 ],\n",
              "       [0.9797662 ],\n",
              "       [0.10141237],\n",
              "       [0.999716  ],\n",
              "       [0.04649662],\n",
              "       [0.38214177],\n",
              "       [0.06227797],\n",
              "       [0.80599517],\n",
              "       [0.9316778 ],\n",
              "       [0.06192844],\n",
              "       [0.00196563],\n",
              "       [0.27289736],\n",
              "       [0.9917024 ],\n",
              "       [0.83377695],\n",
              "       [0.12886557],\n",
              "       [0.43456337],\n",
              "       [0.7352027 ],\n",
              "       [0.02862123],\n",
              "       [0.99234176],\n",
              "       [0.5530986 ],\n",
              "       [0.99892163],\n",
              "       [0.9395176 ],\n",
              "       [0.10240206],\n",
              "       [0.44477266],\n",
              "       [0.12261529],\n",
              "       [0.9420499 ],\n",
              "       [0.7537915 ],\n",
              "       [0.4370669 ],\n",
              "       [0.03789014],\n",
              "       [0.33620068],\n",
              "       [0.0426408 ],\n",
              "       [0.06525583],\n",
              "       [0.16026747],\n",
              "       [0.40025654],\n",
              "       [0.5345048 ],\n",
              "       [0.15799035],\n",
              "       [0.9991216 ],\n",
              "       [0.9878991 ],\n",
              "       [0.28630087],\n",
              "       [0.83657897],\n",
              "       [0.26317325],\n",
              "       [0.04341509],\n",
              "       [0.33901885],\n",
              "       [0.7373321 ],\n",
              "       [0.12098143],\n",
              "       [0.2366258 ],\n",
              "       [0.01680411],\n",
              "       [0.52994096],\n",
              "       [0.00251922],\n",
              "       [0.9541342 ],\n",
              "       [0.9785346 ],\n",
              "       [0.9947542 ],\n",
              "       [0.97781026],\n",
              "       [0.8101345 ],\n",
              "       [0.19781148],\n",
              "       [0.07269226],\n",
              "       [0.63442016],\n",
              "       [0.92156774],\n",
              "       [0.9982889 ],\n",
              "       [0.00280133],\n",
              "       [0.1561759 ],\n",
              "       [0.17075771],\n",
              "       [0.9988703 ],\n",
              "       [0.99947554],\n",
              "       [0.29125142],\n",
              "       [0.16000226],\n",
              "       [0.9972247 ],\n",
              "       [0.058296  ],\n",
              "       [0.34630457],\n",
              "       [0.98634386],\n",
              "       [0.13323368],\n",
              "       [0.05065583],\n",
              "       [0.9393857 ],\n",
              "       [0.37067002],\n",
              "       [0.4386278 ],\n",
              "       [0.9719287 ],\n",
              "       [0.02595352],\n",
              "       [0.06005125],\n",
              "       [0.01280878],\n",
              "       [0.02197529],\n",
              "       [0.125691  ],\n",
              "       [0.975588  ],\n",
              "       [0.02127804],\n",
              "       [0.45719767],\n",
              "       [0.5079449 ],\n",
              "       [0.06950296],\n",
              "       [0.28985125],\n",
              "       [0.08626129],\n",
              "       [0.3744974 ],\n",
              "       [0.99804485],\n",
              "       [0.6282268 ],\n",
              "       [0.15119979],\n",
              "       [0.15368144],\n",
              "       [0.15137938],\n",
              "       [0.07542424],\n",
              "       [0.6952928 ],\n",
              "       [0.0197816 ],\n",
              "       [0.905443  ],\n",
              "       [0.8038468 ],\n",
              "       [0.6043157 ],\n",
              "       [0.67875075],\n",
              "       [0.81162393],\n",
              "       [0.08599589],\n",
              "       [0.32169935],\n",
              "       [0.44573548],\n",
              "       [0.9211459 ],\n",
              "       [0.24753375],\n",
              "       [0.24936587],\n",
              "       [0.38827258],\n",
              "       [0.01415453],\n",
              "       [0.12947783],\n",
              "       [0.40779763],\n",
              "       [0.7790191 ],\n",
              "       [0.12409856],\n",
              "       [0.9920872 ],\n",
              "       [0.9182421 ],\n",
              "       [0.8296867 ],\n",
              "       [0.98645234],\n",
              "       [0.18327193],\n",
              "       [0.07491791],\n",
              "       [0.9136093 ],\n",
              "       [0.18323414],\n",
              "       [0.01820868],\n",
              "       [0.0627341 ],\n",
              "       [0.14215903],\n",
              "       [0.00117752],\n",
              "       [0.8806769 ],\n",
              "       [0.82748985],\n",
              "       [0.8349401 ],\n",
              "       [0.9493798 ],\n",
              "       [0.10708539],\n",
              "       [0.12818001],\n",
              "       [0.68353033],\n",
              "       [0.01513299],\n",
              "       [0.29285303],\n",
              "       [0.13380566],\n",
              "       [0.66604304],\n",
              "       [0.5952892 ],\n",
              "       [0.05703274],\n",
              "       [0.07201554],\n",
              "       [0.50003874],\n",
              "       [0.15909848],\n",
              "       [0.1290052 ],\n",
              "       [0.17680946],\n",
              "       [0.21663406],\n",
              "       [0.9989697 ],\n",
              "       [0.98375547],\n",
              "       [0.41106912],\n",
              "       [0.8496286 ],\n",
              "       [0.9924413 ],\n",
              "       [0.00146709],\n",
              "       [0.97000676],\n",
              "       [0.26871645],\n",
              "       [0.51659584],\n",
              "       [0.27359295],\n",
              "       [0.10689964],\n",
              "       [0.15726621],\n",
              "       [0.02862723],\n",
              "       [0.08821925],\n",
              "       [0.08053739],\n",
              "       [0.7695434 ],\n",
              "       [0.2952358 ],\n",
              "       [0.99432796],\n",
              "       [0.05191846],\n",
              "       [0.71850747],\n",
              "       [0.62969726],\n",
              "       [0.01769174],\n",
              "       [0.06180339],\n",
              "       [0.9633968 ],\n",
              "       [0.7216344 ],\n",
              "       [0.9691205 ],\n",
              "       [0.33427742],\n",
              "       [0.08389525],\n",
              "       [0.48173523],\n",
              "       [0.36071885],\n",
              "       [0.3244999 ],\n",
              "       [0.9924413 ],\n",
              "       [0.01373082],\n",
              "       [0.04547935],\n",
              "       [0.1423526 ],\n",
              "       [0.9968983 ],\n",
              "       [0.23247682],\n",
              "       [0.05343045],\n",
              "       [0.84841263],\n",
              "       [0.08300538],\n",
              "       [0.03144543],\n",
              "       [0.1813696 ],\n",
              "       [0.24316368],\n",
              "       [0.13696733],\n",
              "       [0.32745492],\n",
              "       [0.40084645],\n",
              "       [0.22186887],\n",
              "       [0.09317507],\n",
              "       [0.4140293 ],\n",
              "       [0.02013398],\n",
              "       [0.9393128 ],\n",
              "       [0.85542   ],\n",
              "       [0.5072778 ],\n",
              "       [0.0406162 ],\n",
              "       [0.0230267 ],\n",
              "       [0.9892512 ],\n",
              "       [0.76301044],\n",
              "       [0.99959   ],\n",
              "       [0.35384104],\n",
              "       [0.87764204],\n",
              "       [0.12024554],\n",
              "       [0.61595416],\n",
              "       [0.6949717 ],\n",
              "       [0.02348029],\n",
              "       [0.9821943 ],\n",
              "       [0.10988771],\n",
              "       [0.5493344 ],\n",
              "       [0.99827194],\n",
              "       [0.14872885],\n",
              "       [0.02995812],\n",
              "       [0.31960723],\n",
              "       [0.01313417],\n",
              "       [0.47499675],\n",
              "       [0.9998349 ],\n",
              "       [0.25514928],\n",
              "       [0.9477797 ],\n",
              "       [0.26647428],\n",
              "       [0.7835836 ],\n",
              "       [0.23783651],\n",
              "       [0.25915843],\n",
              "       [0.01692518],\n",
              "       [0.6685525 ],\n",
              "       [0.01636268],\n",
              "       [0.2285796 ],\n",
              "       [0.9468995 ],\n",
              "       [0.93977654],\n",
              "       [0.99540687],\n",
              "       [0.79077625],\n",
              "       [0.05009097],\n",
              "       [0.3497679 ],\n",
              "       [0.01479837],\n",
              "       [0.4386765 ],\n",
              "       [0.36181372],\n",
              "       [0.8956733 ],\n",
              "       [0.04115654],\n",
              "       [0.79500806],\n",
              "       [0.8529207 ],\n",
              "       [0.2682379 ],\n",
              "       [0.21682924],\n",
              "       [0.24936587],\n",
              "       [0.20665579],\n",
              "       [0.43147868],\n",
              "       [0.6843111 ],\n",
              "       [0.9987645 ],\n",
              "       [0.06435596],\n",
              "       [0.00850031],\n",
              "       [0.01996425],\n",
              "       [0.2553301 ],\n",
              "       [0.22797137],\n",
              "       [0.02629401],\n",
              "       [0.81551725],\n",
              "       [0.10968144],\n",
              "       [0.20004292],\n",
              "       [0.26941752],\n",
              "       [0.2320874 ],\n",
              "       [0.9344909 ],\n",
              "       [0.19414748],\n",
              "       [0.57873684],\n",
              "       [0.3161795 ],\n",
              "       [0.01528817],\n",
              "       [0.10869252],\n",
              "       [0.9997377 ],\n",
              "       [0.81638783],\n",
              "       [0.00437637],\n",
              "       [0.387313  ],\n",
              "       [0.17548195],\n",
              "       [0.08708651],\n",
              "       [0.89693004],\n",
              "       [0.5800285 ],\n",
              "       [0.6512687 ],\n",
              "       [0.4105502 ],\n",
              "       [0.21771961],\n",
              "       [0.6808419 ],\n",
              "       [0.16521993],\n",
              "       [0.06179915],\n",
              "       [0.9179712 ],\n",
              "       [0.18603548],\n",
              "       [0.404305  ],\n",
              "       [0.98307794],\n",
              "       [0.32420877],\n",
              "       [0.37353572],\n",
              "       [0.00117752],\n",
              "       [0.3126827 ],\n",
              "       [0.85513014],\n",
              "       [0.999716  ],\n",
              "       [0.70732963],\n",
              "       [0.04908262],\n",
              "       [0.99129   ],\n",
              "       [0.41683862],\n",
              "       [0.87280434],\n",
              "       [0.41683862],\n",
              "       [0.99268204],\n",
              "       [0.01089931],\n",
              "       [0.46528074],\n",
              "       [0.09248223],\n",
              "       [0.9776097 ],\n",
              "       [0.2752024 ],\n",
              "       [0.48588926],\n",
              "       [0.05706698],\n",
              "       [0.3355989 ],\n",
              "       [0.12414259],\n",
              "       [0.01913057],\n",
              "       [0.27068964],\n",
              "       [0.0690092 ],\n",
              "       [0.08466554],\n",
              "       [0.8419721 ],\n",
              "       [0.02321944],\n",
              "       [0.11571278],\n",
              "       [0.03199232],\n",
              "       [0.01848643],\n",
              "       [0.10965295],\n",
              "       [0.69213045],\n",
              "       [0.07321765],\n",
              "       [0.6358595 ],\n",
              "       [0.1545866 ],\n",
              "       [0.1931104 ],\n",
              "       [0.88889426],\n",
              "       [0.16596727],\n",
              "       [0.04172364],\n",
              "       [0.06868455],\n",
              "       [0.00707432],\n",
              "       [0.99075794],\n",
              "       [0.01848643],\n",
              "       [0.4200674 ],\n",
              "       [0.99179405],\n",
              "       [0.99362445],\n",
              "       [0.9974335 ],\n",
              "       [0.9999212 ],\n",
              "       [0.99957734],\n",
              "       [0.24104325],\n",
              "       [0.09355731],\n",
              "       [0.29115716],\n",
              "       [0.5718729 ],\n",
              "       [0.9971621 ],\n",
              "       [0.5454973 ],\n",
              "       [0.26311323],\n",
              "       [0.587835  ],\n",
              "       [0.7487903 ],\n",
              "       [0.03214489],\n",
              "       [0.00588069],\n",
              "       [0.10781263],\n",
              "       [0.37524512],\n",
              "       [0.00916969],\n",
              "       [0.06942253],\n",
              "       [0.39850798],\n",
              "       [0.9914328 ],\n",
              "       [0.02653544],\n",
              "       [0.9278599 ],\n",
              "       [0.71498823],\n",
              "       [0.0794595 ],\n",
              "       [0.3283184 ],\n",
              "       [0.12410508],\n",
              "       [0.8329551 ],\n",
              "       [0.44534975],\n",
              "       [0.01158855]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "model_1_pred_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrAxjCnoW3-H"
      },
      "outputs": [],
      "source": [
        "# From the above, we had condensed our model from 15 vectors of 128 to one vector of 128, by adding a single layer 'globalpoolingaverage1D()'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XuafFG8-tUi"
      },
      "outputs": [],
      "source": [
        "# Next we need to compare apples to apples, in other words our pred probs to the val_labels, we need to convert model prediction probabilities to label format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdyBlg8M-FLi",
        "outputId": "79a986ec-54cd-40c9-99f8-38a05f16f4fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40661392],\n",
              "       [0.83657897],\n",
              "       [0.99749917],\n",
              "       [0.12710689],\n",
              "       [0.10593968],\n",
              "       [0.94930077],\n",
              "       [0.9286818 ],\n",
              "       [0.99326754],\n",
              "       [0.96876615],\n",
              "       [0.28698525]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "model_1_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz_VkhOB-KkJ",
        "outputId": "43d735c3-d299-4083-a500-319ce42f6f5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "val_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYRS1EvC721e",
        "outputId": "05b0fb20-fc94-4a11-85f9-8fed53731b8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # tf.squeeze gets rid of the 1 dimension '1' by size '1' from (762,1) to (762)\n",
        "model_1_preds[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyjMsQiM8CpJ",
        "outputId": "657e282a-eb93-460e-a798-67c9571643c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.95275590551181,\n",
              " 'precision': 0.7816545659065345,\n",
              " 'recall': 0.7795275590551181,\n",
              " 'f1': 0.7774022539420016}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(y_true = val_labels,\n",
        "                                    y_pred = model_1_preds)\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqVYafHx_pk5",
        "outputId": "289141c5-c30a-4266-8d2d-cfc9d83796b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# Now see our baseliine results for comparison (model_0)\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFZd61UA_5F5",
        "outputId": "f6c0e4c7-77e7-4985-d7cc-dd18d811b1b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Comparing both results numerically via numpy\n",
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xq8LxLDQAS64"
      },
      "outputs": [],
      "source": [
        "# All 4 metrics from the baseline_results are higher than model_1_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xa7PtEWH6tw"
      },
      "source": [
        "## Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgXmgGKUC0Da",
        "outputId": "2ee24715-43e0-4ca1-abe5-babc606d6124"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10] # shows the top 10,000 words, though we'll see first 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4GwkLytIJCg",
        "outputId": "2628864c-cf7d-41f6-ae18-c2eb1b9bddcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model_1 summary\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm3nnYWDKEvQ",
        "outputId": "f49b2ed8-e4e0-4f93-b7a0-4605a026a1f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ],
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (these are the numerical representations of each token in our training data, which have been learned for ~5 epochs)\n",
        "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0] # '[0]' to get the first matrix\n",
        "print(embed_weights.shape) # same size as vocab size and embedding_dim (output dim of our embedding layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vROoGEvdKm6Q"
      },
      "outputs": [],
      "source": [
        "# so our embedding matrix has a slot for every token in our vocabulary (10000), with each token embedded into a 128 length vector e.g. [0.365,0.848,0.453,0.932,...,0.910] (0.910 the 128th)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjyvobkENysg",
        "outputId": "39261792-e919-48e2-f526-e787046fc740"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.02356558, -0.02438626,  0.06662467, ...,  0.0025911 ,\n",
              "         0.02161844,  0.00505348],\n",
              "       [ 0.03875388,  0.02505642, -0.0461161 , ..., -0.01898527,\n",
              "         0.00394818,  0.02104901],\n",
              "       [-0.02789298,  0.02657246,  0.00972267, ...,  0.03770961,\n",
              "        -0.02348651, -0.01865199],\n",
              "       ...,\n",
              "       [-0.01165347,  0.01245583, -0.0361015 , ...,  0.00047594,\n",
              "         0.02410677,  0.01299233],\n",
              "       [-0.08914636, -0.01690197,  0.04235037, ...,  0.00556227,\n",
              "        -0.007255  ,  0.0247116 ],\n",
              "       [-0.06976751, -0.03830614,  0.04709632, ..., -0.06313104,\n",
              "        -0.06000149,  0.06617491]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "embed_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlaFWtAhPWCB"
      },
      "source": [
        "Now we've got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it.\n",
        "\n",
        "To do so, TensorFlow has a handy tool called projector: https://projector.tensorflow.org/\n",
        "\n",
        "And TensorFlow also has an incredible guide on word embeddings themselves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwlO34DOsYgk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBHliW5rNz7O"
      },
      "outputs": [],
      "source": [
        "# Create embedding files (we got this from TensoFlow's word embeddings documentation)\n",
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCOTe8Hksxoc"
      },
      "outputs": [],
      "source": [
        "# # Downloadfiles from Colab to upload to projector\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "#   files.download('vectors.tsv')\n",
        "#   files.download('metadata.tsv')\n",
        "# except Exception:\n",
        "#   pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q73B1MjYQmAw"
      },
      "source": [
        "Downloading the files above we can visualize them using https://projector.tensorflow.org/ and clicking the \"load\" button on the left hand side.\n",
        "\n",
        "**Resources:** if you'd like to know more about embeddings, I'd encourage you to check out:\n",
        "* Jay Alammar's visualized word2vec post: https://jalammar.github.io/illustrated-word2vec/\n",
        "* TensorFlow's Word Embeddings guide: https://www.tensorflow.org/text/guide/word_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xqy6ksaRc0LD"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "RNN's are useful for sequence data.\n",
        "\n",
        "The premise of a recurrent neural network is to use the representation of a previous input to aid the representation of a later input.\n",
        "\n",
        "**Resources:** If you want an overview of the internals of a recurrent neural network, see the following: \n",
        "- MIT's sequence modelling lecture: https://www.youtube.com/watch?v=qjrad0V0uJE\n",
        "\n",
        "- Chris Olah's intro to LSTM's: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "\n",
        "- Andrej Karpathy's the unreasonable effectiveness of recurrent neural networks: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "\n",
        "- Alammar's analysis of the Karpathy's rnn effectiveness: https://www.youtube.com/watch?v=o9LEWynwr6g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9u_zyCnc0iI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zJigrKBxZlf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTF1uLqVrqEb"
      },
      "source": [
        "### Model 2: LSTM\n",
        "LSTM = long short term memory (one of the most popular LSTM cells)\n",
        "\n",
        "Our structure of an RNN typically looks like this:\n",
        "\n",
        "`Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Output (label probability)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MOoXWblr1kf"
      },
      "outputs": [],
      "source": [
        "# Create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1, ), dtype = \"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#print(x.shape)\n",
        "#x = layers.LSTM(units = 64, return_sequences=True)(x) # When you are stacking RNN cells together, you need to set return_sequences = True\n",
        "#print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "#print(x.shape)\n",
        "#x = layers.Dense(64, activation = \"relu\")(x)\n",
        "#print(x.shape)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name = \"model_2_LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6ubE4C-FWrQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek3stOp8vQVe",
        "outputId": "7f7cfac8-5315-4082-d7f2-32d2344e3899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XxnU3X6r0vU"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss = \"binary_crossentropy\",\n",
        "               optimizer = tf.keras.optimizers.Adam(),\n",
        "               metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVrjx4XfuVyU",
        "outputId": "09a82691-8f1d-4e6b-e5bc-65040ed31fe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20221002-120009\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 12ms/step - loss: 0.2257 - accuracy: 0.9253 - val_loss: 0.5456 - val_accuracy: 0.7887\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1559 - accuracy: 0.9413 - val_loss: 0.6489 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1240 - accuracy: 0.9533 - val_loss: 0.6861 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.1028 - accuracy: 0.9585 - val_loss: 0.6697 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0830 - accuracy: 0.9672 - val_loss: 0.8830 - val_accuracy: 0.7730\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "model_2.history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs = 5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_2_LSTM\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEKOoJk7uon0",
        "outputId": "84dc4c96-6c71-4576-87de-0cd17f2da523"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.1046540e-02],\n",
              "       [8.9121175e-01],\n",
              "       [9.9986362e-01],\n",
              "       [7.6267540e-02],\n",
              "       [5.8413943e-04],\n",
              "       [9.9916339e-01],\n",
              "       [9.2599988e-01],\n",
              "       [9.9988723e-01],\n",
              "       [9.9983370e-01],\n",
              "       [4.8352557e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# Make predictions with LGTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw013WbGvauF",
        "outputId": "ca441eae-c42e-46e6-9482-ce6256a2aa19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# Convert model_2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG8to0CkwuxV",
        "outputId": "f663b87c-b88c-46ea-b676-c115b03b0058"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.29658792650919,\n",
              " 'precision': 0.7738445106757977,\n",
              " 'recall': 0.7729658792650919,\n",
              " 'f1': 0.7713337273803944}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# Calculate model_2 results\n",
        "model_2_results = calculate_results(y_true = val_labels,\n",
        "                                    y_pred = model_2_preds)\n",
        "model_2_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baflf3Aew7zk",
        "outputId": "07bad4b4-104d-4883-fada-b88df773e66f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.95275590551181,\n",
              " 'precision': 0.7816545659065345,\n",
              " 'recall': 0.7795275590551181,\n",
              " 'f1': 0.7774022539420016}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# See model_1 results\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zb3MtstexOpU",
        "outputId": "e6b681a7-15a6-458c-d0e8-5731785fbad7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# See baseline (model 0) results\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou7HtTBOx2Wt"
      },
      "source": [
        "## Model_3 :GRU (Gated recurrent unit)\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
        "\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pyu1eOphxRql"
      },
      "outputs": [],
      "source": [
        "# Create a GRU model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape = (1, ), dtype = \"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "#print(x.shape)\n",
        "#x = layers.GRU(units = 64, return_sequences = True)(x) # if you want to stack recurrent layers on top of each other, you need recurrent_sequences = True\n",
        "# print(x.shape)\n",
        "#x = layers.LSTM(64, return_sequences = True)(x)\n",
        "# print(x.shape)\n",
        "#x = layers.Dense(64, activation = \"relu\")(x)\n",
        "# print(x.shape)\n",
        "#x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name = \"model_3_GRU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdYRKTnmDOVI",
        "outputId": "46b8967b-ee1e-49d7-ae92-b7d613503a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIfyzF1cDnxN"
      },
      "outputs": [],
      "source": [
        "model_3.compile(loss = \"binary_crossentropy\",\n",
        "                          optimizer = tf.keras.optimizers.Adam(),\n",
        "                          metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jElXuUvmD3hK",
        "outputId": "17c027cb-eaa9-4588-8a2a-93fbeee1809b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20221002-120026\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 11ms/step - loss: 0.1563 - accuracy: 0.9381 - val_loss: 0.7555 - val_accuracy: 0.7848\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0825 - accuracy: 0.9689 - val_loss: 0.8060 - val_accuracy: 0.7717\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0672 - accuracy: 0.9727 - val_loss: 0.9114 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0571 - accuracy: 0.9752 - val_loss: 1.2495 - val_accuracy: 0.7625\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0499 - accuracy: 0.9772 - val_loss: 1.0437 - val_accuracy: 0.7743\n"
          ]
        }
      ],
      "source": [
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(SAVE_DIR, \n",
        "                                                                       \"model_3_GRU\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1A_m7WuDZPJ",
        "outputId": "aed6c559-1de8-44dd-9310-70a603652fad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.3779262e-03],\n",
              "       [8.6996049e-01],\n",
              "       [9.9987388e-01],\n",
              "       [1.3905753e-01],\n",
              "       [1.6747060e-04],\n",
              "       [9.9964023e-01],\n",
              "       [8.9114064e-01],\n",
              "       [9.9995852e-01],\n",
              "       [9.9990320e-01],\n",
              "       [9.8840547e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLZQMaOtR_Rc",
        "outputId": "0c05db1b-edd8-4061-eeb5-672406dd057b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3y57idVRg74",
        "outputId": "c594ce0e-7c9d-43f0-b83f-1a93b799034b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.42782152230971,\n",
              " 'precision': 0.7757380419380466,\n",
              " 'recall': 0.7742782152230971,\n",
              " 'f1': 0.7723566516531356}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "# Calculate model_3 results\n",
        "model_3_results = calculate_results(y_true = val_labels,\n",
        "                                         y_pred = model_3_preds\n",
        "                                         )\n",
        "model_3_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6T3wdqgRvUo",
        "outputId": "df8cdc51-6b3c-430f-aad0-524a7bb145e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLSe4JaBiDrV"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNN's go from left to right (just like you'd read an English sentence) however, a bidireectional RNN goes from right to left as well as left to right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ukT_brhq5uH"
      },
      "outputs": [],
      "source": [
        "# Create the layers of our bidirectional model_4\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape = (1, ), dtype = \"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "#x = layers.Bidirectional(layers.LSTM(64, return_sequences = True))(x)\n",
        "#x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name = \"model_4_Bidirectional_LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQkrb4XBKcxr",
        "outputId": "6c3e126d-cff4-4159-b49b-9138150db44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              98816     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_4.summary() # bidirectional doubles the vector value e.g 64 to 128 as it reads left to right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK8aa-KXKiIz"
      },
      "outputs": [],
      "source": [
        "# Compile our model\n",
        "model_4.compile(loss = tf.keras.losses.binary_crossentropy,\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpiF9Q7eLkUb",
        "outputId": "0db4e172-6c81-42f4-d6c9-3dab004dfe3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20221002-120041\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 16ms/step - loss: 0.1106 - accuracy: 0.9625 - val_loss: 0.9418 - val_accuracy: 0.7651\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0518 - accuracy: 0.9764 - val_loss: 1.2554 - val_accuracy: 0.7690\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0444 - accuracy: 0.9801 - val_loss: 1.1849 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0418 - accuracy: 0.9822 - val_loss: 1.1810 - val_accuracy: 0.7703\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.0397 - accuracy: 0.9815 - val_loss: 1.5229 - val_accuracy: 0.7651\n"
          ]
        }
      ],
      "source": [
        "# Fit our model\n",
        "history_model_4 = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(SAVE_DIR, \"model_4_bidirectional\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LktV3CvlMLYr",
        "outputId": "f2a9979c-7f4a-47e8-b506-dce4cc71f35f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0158619e-02],\n",
              "       [6.9689065e-01],\n",
              "       [9.9997497e-01],\n",
              "       [1.8389753e-01],\n",
              "       [1.1384934e-05],\n",
              "       [9.9987292e-01],\n",
              "       [9.9788046e-01],\n",
              "       [9.9998796e-01],\n",
              "       [9.9997437e-01],\n",
              "       [9.9945110e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZzzB64GMotL",
        "outputId": "838bedb0-e94d-46bc-fe71-b4a01024ae57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "#convert pred_probs to pred labels\n",
        "model_4_probs = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B2rlmAyM7xb",
        "outputId": "a045fe6e-9b7b-4979-9608-230be6c6b0f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.50918635170603,\n",
              " 'precision': 0.7649467964142894,\n",
              " 'recall': 0.7650918635170604,\n",
              " 'f1': 0.7650074262541928}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "# Calculate results from our model_4\n",
        "model_4_results = calculate_results(y_true = val_labels,\n",
        "                                    y_pred = model_4_probs)\n",
        "model_4_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DZehC7iNVI6",
        "outputId": "d2a2835f-80bb-4e08-e5cc-d369f988fd33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.42782152230971,\n",
              " 'precision': 0.7757380419380466,\n",
              " 'recall': 0.7742782152230971,\n",
              " 'f1': 0.7723566516531356}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "# See our model_3 results\n",
        "model_3_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGYwW9wmNizr"
      },
      "outputs": [],
      "source": [
        "# Bidirectionality has given worse results, though try to best the baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTPBT8n7T1Rx"
      },
      "source": [
        "## Convolutional Neural Networks for Text (and other types of sequences)\n",
        "\n",
        "We've used CNNs for images but images are typically 2D (height x width)... however our text data is 1D.\n",
        "\n",
        "Previously we've Conv2D for our image data but now we're going to use Conv1D\n",
        "\n",
        "The typical struction of a Conv1D model for sequences (in our case, text):\n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + pooling) -> Outputs (class probabilities\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLVxoXxKUrP7"
      },
      "source": [
        "### Model 5: Conv1D\n",
        "For different explanations of parameters see:\n",
        "* https://poloclub.github.io/cnn-explainer/\n",
        "* Same vs valid padding: https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2A9RtA9X7EG",
        "outputId": "7f1f8a66-f0f3-44a6-ff67-f6c0d9557bf4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "# Test out our embedding layer, Conv1D layer and max pooling\n",
        "from tensorflow.keras import layers\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sequence into an embedding\n",
        "conv_1d = layers.Conv1D(filters = 32, # this also referred to an ngram of 5 (meaning it looks at 5 words at a time)\n",
        "                        kernel_size = 5,\n",
        "                        strides = 1, # default\n",
        "                        activation = \"relu\",\n",
        "                        padding = \"valid\") # default = \"valid\", the output is smaller than the input shape, and \"same\" is output the same shape as input \n",
        "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
        "max_pool = layers.GlobalMaxPool1D() # GlobalMaxPool takes the maximum across a given dimension, while GlobalAveragePool takes the aveage dimension\n",
        "max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature\" or \" get the feature with the maximum value\"\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSdWvw6xUpJf"
      },
      "outputs": [],
      "source": [
        "#embedding_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cgq8NyodN-w"
      },
      "outputs": [],
      "source": [
        "#conv_1d_output # many '0's' because relu converts negative values to '0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4dBWP63dR3R"
      },
      "outputs": [],
      "source": [
        "#max_pool_output # we condense it into a single feature vector of size '32'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0TEVpcVo_6j",
        "outputId": "1dc238e4-32ab-498b-ccc6-461e413d4989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create the layers of our bidirectional model_4\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string) # shape set to one sequence per input\n",
        "x = text_vectorizer(inputs) # map our inputs into integers\n",
        "x = embedding(x) # embed the integer form of our inputs, to represent them as tensors\n",
        "x = layers.Conv1D(filters = 64, kernel_size = 5, strides=1, activation = \"relu\", padding = \"valid\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(1, activation = \"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name = \"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])\n",
        "\n",
        "# Get a summary of our Conv1D model\n",
        "model_5.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnnDJnf6pqxz",
        "outputId": "2e97126d-ac62-48c5-e1b7-c81cbc741294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_Conv1D/20221002-120113\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 8ms/step - loss: 0.1236 - accuracy: 0.9593 - val_loss: 0.8972 - val_accuracy: 0.7743\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 5ms/step - loss: 0.0733 - accuracy: 0.9730 - val_loss: 1.0045 - val_accuracy: 0.7717\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.0604 - accuracy: 0.9771 - val_loss: 1.1053 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.0561 - accuracy: 0.9747 - val_loss: 1.1800 - val_accuracy: 0.7585\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.0503 - accuracy: 0.9783 - val_loss: 1.2011 - val_accuracy: 0.7598\n"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                       \"model_5_Conv1D\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDIgEKMixr5R",
        "outputId": "c69eb4d8-b0d2-408b-8473-71bc4f53cd54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1376977e-01],\n",
              "       [6.7127478e-01],\n",
              "       [9.9995685e-01],\n",
              "       [5.5535093e-02],\n",
              "       [5.1719081e-08],\n",
              "       [9.9346018e-01],\n",
              "       [9.8553813e-01],\n",
              "       [9.9996185e-01],\n",
              "       [9.9999952e-01],\n",
              "       [8.7208998e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "# Make some predictions with our Conv1D model\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP6TTp9QyElj",
        "outputId": "4c5eca5d-8b5f-4f3f-efb4-96c6ada559fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "# Change our pred probabilities to label format\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dJU-42qyP_z",
        "outputId": "3579ccb7-089c-4a58-98d8-f9e034c9a5dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.98425196850394,\n",
              " 'precision': 0.7601337255372377,\n",
              " 'recall': 0.7598425196850394,\n",
              " 'f1': 0.7583542786286791}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "# Calculate results from our model 5\n",
        "model_5_results = calculate_results(y_pred = model_5_preds,\n",
        "                                    y_true = val_labels)\n",
        "model_5_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3EahcjkypoC",
        "outputId": "b454550f-a824-46aa-dfc7-3767d65f7f6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci2M1WS3zqTi"
      },
      "source": [
        "## Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "Now we've built a few of our own models, let's try and use transfer learning for NLP, specifically using TensorFlow Hub's Universal Sentence Encoder: https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "Seehow the USE is trained here: https://arxiv.org/abs/1803.11175\n",
        "\n",
        "USE stands for Universal Sentence Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_dG5MmR7ltoF",
        "outputId": "ac9d4085-b6e4-4cd1-a839-8fbb1e24dc3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"There's a flood in my street!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "sample_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TOUzAToy5bE",
        "outputId": "0713324b-d84d-4154-ceda-834ea3bc5e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157032  0.02485909  0.02878048 -0.01271501  0.03971539  0.0882776\n",
            "  0.02680985  0.05589837 -0.0106873  -0.00597291  0.00639325 -0.0181952\n",
            "  0.00030816  0.09105889  0.05874643 -0.03180627  0.01512473 -0.05162929\n",
            "  0.00991365 -0.06865346 -0.04209305  0.02678981  0.03011008  0.00321067\n",
            " -0.0033797  -0.04787361  0.02266722 -0.00985925 -0.04063613 -0.0129209\n",
            " -0.04666385  0.056303   -0.03949255  0.00517688  0.02495828 -0.07014443\n",
            "  0.02871508  0.04947681 -0.00633976 -0.08960193  0.02807116 -0.00808363\n",
            " -0.01360604  0.0599865  -0.10361787 -0.05195372  0.00232956 -0.02332528\n",
            " -0.03758106  0.03327731], shape=(50,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       \"When you can the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "print(embed_samples[0][:50]) # get the first, and first 50 samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDsufQy0b6Rx",
        "outputId": "32e4683e-5069-48f9-889c-d5c9bc52d9cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 512), dtype=float32, numpy=\n",
              "array([[-0.01157032,  0.02485909,  0.02878048, ..., -0.00186123,\n",
              "         0.02315825, -0.01485021],\n",
              "       [ 0.03485871, -0.08845593, -0.01677878, ..., -0.02750705,\n",
              "         0.03230238, -0.00820086]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "embed_samples # when we pass 'sample_sentence' through the pretrained universal sentence encoder, this is what it outputs (first '50' embedding values) - turned our sentence into a numerical representation, a feature vector of 512 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q6YhHlgdj55",
        "outputId": "d0c0496f-446d-4ad7-a6ad-4d578f69395e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "embed_samples.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIwfLnifrJZl"
      },
      "outputs": [],
      "source": [
        "# Create a Keras Layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfkOBjAtrIRC"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAnl3xE_lb0m",
        "outputId": "820f1e3b-d99d-4262-e9eb-63009a62e9c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "embed_samples[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-D6X1CNleos"
      },
      "outputs": [],
      "source": [
        "# Create a Keras Layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape = [],\n",
        "                                        dtype = tf.string,\n",
        "                                        trainable = False,\n",
        "                                        name = \"USE\") # empty vector, because the input to this layer can be of any variable length, though always output a 512 feature vector regardless.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCwvOtT5lIAK",
        "outputId": "d7c2dc93-b7e1-4d33-ab18-cc33aeefbd8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " relu_layer_1 (Dense)        (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer, # we don't need a text vectorization layer, as the USE module handles that for us\n",
        "    layers.Dense(64, activation = \"relu\", name = \"relu_layer_1\"),\n",
        "    #layers.Dense(64, activation = \"relu\", name = \"relu_layer_2\"),\n",
        "    layers.Dense(1, activation = \"sigmoid\", name = \"output_layer\") # we are working on a binary classification problem\n",
        "], name = \"model_6_USE\")\n",
        "\n",
        "# Compile\n",
        "model_6.compile(loss = \"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN2Jz86KoKPY"
      },
      "source": [
        "Advantage of using a pretrained model like USE is that they are already trained, leaving us only training the dense layer (the output) layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpoQXjmGnvH9",
        "outputId": "a62a20e9-77f5-40c8-ac92-08337548343e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20221002-120153\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 18ms/step - loss: 0.5028 - accuracy: 0.7755 - val_loss: 0.4489 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.4153 - accuracy: 0.8145 - val_loss: 0.4375 - val_accuracy: 0.8084\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.4003 - accuracy: 0.8216 - val_loss: 0.4348 - val_accuracy: 0.8123\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3930 - accuracy: 0.8269 - val_loss: 0.4301 - val_accuracy: 0.8123\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.3859 - accuracy: 0.8295 - val_loss: 0.4445 - val_accuracy: 0.8005\n"
          ]
        }
      ],
      "source": [
        "# Train a classifier on top of USE pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks = create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                      \"tf_hub_sentence_encoder\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SyOPq2Vq-YM",
        "outputId": "a750b117-d555-43c7-cf55-f39713963b5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11733251],\n",
              "       [0.63533396],\n",
              "       [0.9854388 ],\n",
              "       [0.19736943],\n",
              "       [0.64113843],\n",
              "       [0.59806424],\n",
              "       [0.96564376],\n",
              "       [0.96115464],\n",
              "       [0.8800834 ],\n",
              "       [0.08659372],\n",
              "       [0.57058924],\n",
              "       [0.38508287],\n",
              "       [0.12238693],\n",
              "       [0.34724176],\n",
              "       [0.161966  ],\n",
              "       [0.0227721 ],\n",
              "       [0.3075304 ],\n",
              "       [0.53729856],\n",
              "       [0.2713363 ],\n",
              "       [0.24727026]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "# Get our model 6's predictions\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wio7PnyarWcs",
        "outputId": "b9ef17b0-8b26-468d-ad68-f6bfc3cb0b8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "# Convert our USE TF Hub model predictions to a label format\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFfKG76irptc",
        "outputId": "bcd826df-a1ba-4740-9520-3bdbdfe82e08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.0524934383202,\n",
              " 'precision': 0.8097952566853514,\n",
              " 'recall': 0.800524934383202,\n",
              " 'f1': 0.7966840570849284}"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "# Calculate our model 6's performance metrics\n",
        "model_6_results = calculate_results(y_pred = model_6_preds,\n",
        "                                    y_true = val_labels)\n",
        "model_6_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT0YJXG4sLxs",
        "outputId": "79bf5edd-e329-46df-987a-404db4885bf1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "baseline_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v34Qf8uasPUc",
        "outputId": "85b041ed-84d4-480e-948e-fe997fbc70d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "len(train_df_shuffled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTpUXBIhv2d_"
      },
      "source": [
        "## Model 7: TF Hub Pretrained USE but with 10% of training data\n",
        "\n",
        "Transfer learning really helps when you don't have a large dataset.\n",
        "\n",
        "To see how our model performs on a smaller dataset, let's replicate `model_6` except we'll train it on 10% of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rqkdm98KvF-N"
      },
      "outputs": [],
      "source": [
        "# ## NOTE: Making data splits like below leads to data leakage (model_7 trained on 10% data, outperforms model_6 trained on 100% data)\n",
        "# ## DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION/TEST SETS INTO TRAINING SET\n",
        "# # Create subsets of 10% of the training data\n",
        "# train_10_percent = train_df_shuffled[[\"text\", \"target\"]].sample(frac = 0.1, random_state = 42) # 'frac' is 10% of train data\n",
        "# #train_10_percent.head(), len(train_10_percent)\n",
        "# train_sentences_10_percent = train_10_percent[\"text\"].to_list() # 'to_list' changes a series to a list\n",
        "# train_labels_10_percent = train_10_percent[\"target\"].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-gSU06UPTKa"
      },
      "source": [
        "**Note:** Be *very* careful when creating training/val/test splits that you don't leak data across the datasets, otherwise your model evaluation metrics will be wrong. If something looks too good to be true (a model trained on 10% of data outperforming the same model trained on 100% of data) trust your gut and go back through to find where the error may lie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E98pyYqEHdDQ",
        "outputId": "f877c2e6-7dd3-4d90-aa2d-5be1a9df1309"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "685"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "# Making a better dataset split (no data leakage)\n",
        "train_sentences_10_percent_split = int(0.1 * len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_sentences_10_percent_split]\n",
        "#len(train_10_percent)\n",
        "train_labels_10_percent = train_labels[:train_sentences_10_percent_split]\n",
        "len(train_labels_10_percent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EkOobBIIoyG",
        "outputId": "5591efd0-e28b-48af-b1bc-1ba49a353d62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    406\n",
              "1    279\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "# Check the number of each label in the updated training data subset\n",
        "# y = np.array(train_labels_10_percent)\n",
        "\n",
        "# np.bincount(y)#.sum()\n",
        "\n",
        "#or\n",
        "pd.Series(np.array(train_labels_10_percent)).value_counts() # not perfect match to train_df_shuffled but will do"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VV9V_Auyz42"
      },
      "source": [
        "Roughly 10% of our shuffled 'train_df_shuffled' dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CEi3rn9yvIz",
        "outputId": "e9645200-4176-4c66-d528-dbdb57459431"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "# Check the number of targets in our subset of data\n",
        "train_df_shuffled[\"target\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHWT8C7-wrOt"
      },
      "outputs": [],
      "source": [
        "#approx 60:40 ratio across both value_counts the full and 10%. Both are representive.\n",
        "# Whenever you are making a split in your dataset, ensure both sets are from the same distribution as the other one. This can be done randomally,"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1_-mDiMAwlF"
      },
      "source": [
        "To recreate a model the same as the previous model you've created, you can use the `tf.keras.models.clone_model()` method, see more here: https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx4ci28k_y22",
        "outputId": "b5c950dd-dea0-478c-f5b1-17aa06a21b93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " relu_layer_1 (Dense)        (None, 64)                32832     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Let's build a model the same as model_6\n",
        "#model_7  = tf.keras.models.clone_model(model_6) # handy but can't rename it\n",
        "model_7 = tf.keras.Sequential([\n",
        "    sentence_encoder_layer, # we don't need a text vectorization layer, as the USE module handles that for us\n",
        "    layers.Dense(64, activation = \"relu\", name = \"relu_layer_1\"),\n",
        "    #layers.Dense(64, activation = \"relu\", name = \"relu_layer_2\"),\n",
        "    layers.Dense(1, activation = \"sigmoid\", name = \"output_layer\") # we are working on a binary classification problem\n",
        "], name = \"model_7_USE\")\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss = \"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])\n",
        "\n",
        "# Get a summary (will be the same as model_6)\n",
        "model_7.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe4EIIoeCEYH",
        "outputId": "97d51608-7f4d-4219-a6ec-fd886a97685b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_use_10_percent_correct_split/20221002-120215\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 2s 50ms/step - loss: 0.6718 - accuracy: 0.6292 - val_loss: 0.6548 - val_accuracy: 0.6575\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 28ms/step - loss: 0.6058 - accuracy: 0.7752 - val_loss: 0.5999 - val_accuracy: 0.7520\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 29ms/step - loss: 0.5334 - accuracy: 0.8219 - val_loss: 0.5458 - val_accuracy: 0.7703\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 26ms/step - loss: 0.4680 - accuracy: 0.8248 - val_loss: 0.5093 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 34ms/step - loss: 0.4245 - accuracy: 0.8263 - val_loss: 0.4898 - val_accuracy: 0.7730\n"
          ]
        }
      ],
      "source": [
        "# Fit the model to the 10% training data\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs = 5,\n",
        "                              validation_data = (val_sentences, val_labels),\n",
        "                              callbacks = [create_tensorboard_callback(SAVE_DIR, \"tf_hub_use_10_percent_correct_split\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMe9SZlnC-_n",
        "outputId": "bce9bf24-f637-453d-f48d-386f1351cd5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20169467],\n",
              "       [0.59156674],\n",
              "       [0.9066186 ],\n",
              "       [0.36478794],\n",
              "       [0.5907522 ],\n",
              "       [0.6980603 ],\n",
              "       [0.8600193 ],\n",
              "       [0.82217526],\n",
              "       [0.8498025 ],\n",
              "       [0.15445231]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAu1ohWhDm92",
        "outputId": "792e4543-2a59-4a80-ad1d-1ad60148c738"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "# Turn pred probs into labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7CM9_pwD2tm",
        "outputId": "a1fee6e9-2caa-46dc-966c-8fed245fd4f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.29658792650919,\n",
              " 'precision': 0.7730528656214299,\n",
              " 'recall': 0.7729658792650919,\n",
              " 'f1': 0.7718716556605149}"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "# Evaluate model 7 predictions\n",
        "model_7_results = calculate_results(y_pred = model_7_preds,\n",
        "                                    y_true = val_labels)\n",
        "model_7_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oyn7BA4VEDmZ",
        "outputId": "3ba741df-abf2-41fe-dada-ce7e69244340"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.0524934383202,\n",
              " 'precision': 0.8097952566853514,\n",
              " 'recall': 0.800524934383202,\n",
              " 'f1': 0.7966840570849284}"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "model_6_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DAKPCYLQMHx"
      },
      "source": [
        "Model 7, even though trained 10% of the data used by model_6, still performs very well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq1sX31OQ9jb"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76ToA_H3fmR4"
      },
      "source": [
        "## Comparing the performance of each of our models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc0KnJhwfrNR"
      },
      "outputs": [],
      "source": [
        "# Combine model results into a dataframe\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"1_simple_dense\" : model_1_results,\n",
        "                                  \"2_lstm\" : model_2_results,\n",
        "                                  \"3_gru\" : model_3_results,\n",
        "                                  \"4_bidirectional\" : model_4_results,\n",
        "                                  \"5_convld\" : model_5_results,\n",
        "                                  \"6_tf_hub_use_encoder\" : model_6_results,\n",
        "                                  \"7_tf_hub_use_encoder_10_percent\" : model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "#all_model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfdDJQZ0g2bl"
      },
      "outputs": [],
      "source": [
        "# Reduce the accuracy to the same scale as the other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "#all_model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "Lt0Zmf2tibzR",
        "outputId": "a210f9c7-059f-4841-9045-756b07d50e37"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot and comparea all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor = (1.0, 1.0));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "wYaplsKXkWjy",
        "outputId": "7dcf5d7c-d6b8-4a69-bf0d-09b5cb3a8e48"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAI9CAYAAAAev/3CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhldXnu/e/dDCIIoqGjhjkGNR0H1BYVNRqHiEcBFXMCUYPRSHwjwgnneF6MiQMmr0qMiSbkjcQ4YRRxiq1B0XhQoiLSICpDSFocAKNpURGHAI3P+WOtondXV3cVrF21VtX6fq6rrtpr6KqHRXfVvX9jqgpJkiTdPqv6LkCSJGk5M0xJkiR1YJiSJEnqwDAlSZLUgWFKkiSpgx37+sZ77bVXHXDAAX19e0mSpAW76KKLvltVq+e61luYOuCAA1i/fn1f316SJGnBknxjW9fs5pMkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSBwsKU0kOS3Jlkg1JTp7j+n5Jzk3yxSRfTvLfpl+qJEnS8MwbppLsAJwGPAlYAxyTZM2s2/4IOKuqHggcDfzNtAuVJEkaooW0TB0CbKiqq6rqJuBM4MhZ9xSwR/v6zsC3pleiJEnScC0kTO0NXD1xfE17btIrgGcluQY4G3jRXF8oyXFJ1idZv3HjxttRriRJ0rDsOKWvcwzwtqr68yQPB85Ict+q+tnkTVV1OnA6wNq1a2sa3/iAk/9pGl+ms6+/5sl9lyBJknqwkJapa4F9J473ac9Neh5wFkBVnQ/sAuw1jQIlSZKGbCFh6kLgoCQHJtmZZoD5uln3fBN4HECSX6YJU/bjSZKkFW/eMFVVm4DjgXOAK2hm7V2W5JQkR7S3/U/g+Um+BLwbeE5VTaUbT5IkacgWNGaqqs6mGVg+ee5lE68vBx4x3dIkSZKGb1oD0DUgQxmUDw7MlyStfG4nI0mS1IFhSpIkqQPDlCRJUgeOmdJoOJZMkrQYbJmSJEnqwJYpaeRssZOkbgxTkjSHoYTMIQXMoTwTGNZzkezmkyRJ6sAwJUmS1IHdfJIkdWD3p2yZkiRJ6sAwJUmS1IHdfJIkaerG1P1py5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSepgQWEqyWFJrkyyIcnJc1z/iySXtB//luQH0y9VkiRpeHac74YkOwCnAU8ArgEuTLKuqi6fuaeq/mDi/hcBD1yEWiVJkgZnIS1ThwAbquqqqroJOBM4cjv3HwO8exrFSZIkDd1CwtTewNUTx9e057aSZH/gQOD/bOP6cUnWJ1m/cePG21qrJEnS4Ex7APrRwPuq6pa5LlbV6VW1tqrWrl69esrfWpIkaektJExdC+w7cbxPe24uR2MXnyRJGpGFhKkLgYOSHJhkZ5rAtG72TUnuA9wFOH+6JUqSJA3XvGGqqjYBxwPnAFcAZ1XVZUlOSXLExK1HA2dWVS1OqZIkScMz79IIAFV1NnD2rHMvm3X8iumVJUmStDy4ArokSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdbCgMJXksCRXJtmQ5ORt3PPfk1ye5LIk75pumZIkScO043w3JNkBOA14AnANcGGSdVV1+cQ9BwEvAR5RVd9P8vOLVbAkSdKQLKRl6hBgQ1VdVVU3AWcCR8665/nAaVX1fYCq+s/plilJkjRMCwlTewNXTxxf056bdC/gXkk+m+TzSQ6b6wslOS7J+iTrN27cePsqliRJGpBpDUDfETgIeAxwDPB3SfacfVNVnV5Va6tq7erVq6f0rSVJkvqzkDB1LbDvxPE+7blJ1wDrqurmqvoa8G804UqSJGlFW0iYuhA4KMmBSXYGjgbWzbrnH2lapUiyF02331VTrFOSJGmQ5g1TVbUJOB44B7gCOKuqLktySpIj2tvOAa5LcjlwLvDiqrpusYqWJEkainmXRgCoqrOBs2ede9nE6wJOaj8kSZJGwxXQJUmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktTBgsJUksOSXJlkQ5KT57j+nCQbk1zSfvzu9EuVJEkanh3nuyHJDsBpwBOAa4ALk6yrqstn3fqeqjp+EWqUJEkarIW0TB0CbKiqq6rqJuBM4MjFLUuSJGl5WEiY2hu4euL4mvbcbEcl+XKS9yXZd64vlOS4JOuTrN+4cePtKFeSJGlYpjUA/cPAAVV1f+ATwNvnuqmqTq+qtVW1dvXq1VP61pIkSf1ZSJi6FphsadqnPXerqrquqm5sD98MPHg65UmSJA3bQsLUhcBBSQ5MsjNwNLBu8oYk95g4PAK4YnolSpIkDde8s/mqalOS44FzgB2At1TVZUlOAdZX1TrghCRHAJuA7wHPWcSaJUmSBmPeMAVQVWcDZ88697KJ1y8BXjLd0iRJkobPFdAlSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqYMFhakkhyW5MsmGJCdv576jklSStdMrUZIkabjmDVNJdgBOA54ErAGOSbJmjvt2B04ELph2kZIkSUO1kJapQ4ANVXVVVd0EnAkcOcd9rwJeC/zXFOuTJEkatIWEqb2BqyeOr2nP3SrJg4B9q+qftveFkhyXZH2S9Rs3brzNxUqSJA1N5wHoSVYBrwf+53z3VtXpVbW2qtauXr2667eWJEnq3ULC1LXAvhPH+7TnZuwO3Bf4VJKvAw8D1jkIXZIkjcFCwtSFwEFJDkyyM3A0sG7mYlVdX1V7VdUBVXUA8HngiKpavygVS5IkDci8YaqqNgHHA+cAVwBnVdVlSU5JcsRiFyhJkjRkOy7kpqo6Gzh71rmXbePex3QvS5IkaXlwBXRJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdbCgMJXksCRXJtmQ5OQ5rr8gyVeSXJLkM0nWTL9USZKk4Zk3TCXZATgNeBKwBjhmjrD0rqq6X1UdDJwKvH7qlUqSJA3QQlqmDgE2VNVVVXUTcCZw5OQNVfXDicPdgJpeiZIkScO14wLu2Ru4euL4GuChs29K8kLgJGBn4LFzfaEkxwHHAey33363tVZJkqTBmdoA9Ko6raruCfy/wB9t457Tq2ptVa1dvXr1tL61JElSbxYSpq4F9p043qc9ty1nAk/tUpQkSdJysZAwdSFwUJIDk+wMHA2sm7whyUETh08G/n16JUqSJA3XvGOmqmpTkuOBc4AdgLdU1WVJTgHWV9U64PgkjwduBr4PHLuYRUuSJA3FQgagU1VnA2fPOveyidcnTrkuSZKkZcEV0CVJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpgwWFqSSHJbkyyYYkJ89x/aQklyf5cpJPJtl/+qVKkiQNz7xhKskOwGnAk4A1wDFJ1sy67YvA2qq6P/A+4NRpFypJkjREC2mZOgTYUFVXVdVNwJnAkZM3VNW5VfWT9vDzwD7TLVOSJGmYFhKm9gaunji+pj23Lc8DPjrXhSTHJVmfZP3GjRsXXqUkSdJATXUAepJnAWuBP5vrelWdXlVrq2rt6tWrp/mtJUmSerHjAu65Fth34nif9twWkjweeCnw6Kq6cTrlSZIkDdtCWqYuBA5KcmCSnYGjgXWTNyR5IPAm4Iiq+s/plylJkjRM84apqtoEHA+cA1wBnFVVlyU5JckR7W1/BtwJeG+SS5Ks28aXkyRJWlEW0s1HVZ0NnD3r3MsmXj9+ynVJkiQtC66ALkmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQOFhSmkhyW5MokG5KcPMf1X01ycZJNSZ4x/TIlSZKGad4wlWQH4DTgScAa4Jgka2bd9k3gOcC7pl2gJEnSkO24gHsOATZU1VUASc4EjgQun7mhqr7eXvvZItQoSZI0WAvp5tsbuHri+Jr23G2W5Lgk65Os37hx4+35EpIkSYOypAPQq+r0qlpbVWtXr169lN9akiRpUSwkTF0L7DtxvE97TpIkafQWEqYuBA5KcmCSnYGjgXWLW5YkSdLyMG+YqqpNwPHAOcAVwFlVdVmSU5IcAZDkIUmuAX4DeFOSyxazaEmSpKFYyGw+qups4OxZ51428fpCmu4/SZKkUXEFdEmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqwDAlSZLUgWFKkiSpA8OUJElSB4YpSZKkDgxTkiRJHRimJEmSOjBMSZIkdWCYkiRJ6sAwJUmS1IFhSpIkqQPDlCRJUgeGKUmSpA4MU5IkSR0YpiRJkjowTEmSJHVgmJIkSerAMCVJktSBYUqSJKkDw5QkSVIHhilJkqQODFOSJEkdGKYkSZI6MExJkiR1YJiSJEnqYEFhKslhSa5MsiHJyXNcv0OS97TXL0hywLQLlSRJGqJ5w1SSHYDTgCcBa4BjkqyZddvzgO9X1S8BfwG8dtqFSpIkDdFCWqYOATZU1VVVdRNwJnDkrHuOBN7evn4f8LgkmV6ZkiRJw5Sq2v4NyTOAw6rqd9vjZwMPrarjJ+65tL3nmvb4q+093531tY4DjmsP7w1cOa3/kI72Ar47713j43PZms9kbj6Xuflc5uZz2ZrPZG5Dei77V9XquS7suJRVVNXpwOlL+T0XIsn6qlrbdx1D43PZms9kbj6Xuflc5uZz2ZrPZG7L5bkspJvvWmDfieN92nNz3pNkR+DOwHXTKFCSJGnIFhKmLgQOSnJgkp2Bo4F1s+5ZBxzbvn4G8H9qvv5DSZKkFWDebr6q2pTkeOAcYAfgLVV1WZJTgPVVtQ74e+CMJBuA79EEruVkcF2PA+Fz2ZrPZG4+l7n5XObmc9maz2Ruy+K5zDsAXZIkSdvmCuiSJEkdGKYkSZI6MExJkiR1MMowlWRVkkP7rkOSJC1/ox2AnuSLVfXAvusYoiSPBA6qqrcmWQ3cqaq+1nddQ5Bk16r6Sd91DEGSX53rfFWdt9S1DEmSM6rq2fOdG6Mkd6FZk/DWmeRVdXF/FfUjydO3d72qPrBUtQxJkpO2d72qXr9UtdxWS7oC+sB8MslRwAdcE2uzJC8H1tJs9/NWYCfgncAj+qyrb21L5puBOwH7JXkA8HtV9fv9VtarF0+83oVmH8+LgMf2U85g/MrkQbtZ/IN7qmUwkrwKeA7wVWDmZ24xzr8vh2/nWgGjDFPA7u3newMPYfOalocDX+ilogUac8vUDcBuwC3AT4EAVVV79FpYz5JcAjwQuHim5S7Jl6vq/v1W1q8kF9AsSLtu4rlcWlX37bey4UiyL/CXVXVU37X0IclLgD8E7gjMtF4GuAk4vape0ldtQ5DkSuB+VXVT37Vo2JKcBzy5qm5oj3cH/qmq5mwNH4LRtkxV1e7z3zVKN1VVJSmAJLv1XdBQVNXVSSZP3dJXLQN1DfDLfRfRl6p6NfDqJK8ee3DahkuBPYH/7LuQIUnyZJrWzF1mzlXVKf1VNAh3o3kTMuOm9txgjTZMpfmt+EzgwKp6Vfuu+h5VNeimxCVwVpI3AXsmeT7wXODveq5pCK5uu/oqyU7AicAVPdfUqyR/xebumlXAwcDoxr/MVlUvSbI3sD9bjg0a9Vgy4NXAF5NcCtw4c7KqjuivpH4l+VtgV+DXaIYRPIOBd2ctkXcAX0jywfb4qcDb+itnfmPu5vv/gZ8Bj62qX24HRn68qh7Sc2m9S/IE4NdpuijOqapP9FxS75LsBbwBeDzNc/k4cGJVjXZD7yTHThxuAr5eVZ/tq56hSPIami21Lmdz62WNOTQAJLkMeBPwFZqfvQBU1ad7K6pnM0MoJj7fCfhoVT2q79r6luRBwMxzOK+qvthnPfMZbcsU8NCqelCSLwJU1ffbjZxHrw1Pow9Qk6rquzQtmeLWQdW/XlU+k609Dbh3Vd04753j8pOqemPfRQzMT9vPP0nyC8B1wD16rKdXSe46cfj19uPWa1X1vaWuaaHGHKZubn8hzIwNWs3Eu6Wxaqfsvhb4eZoWGAfmA0lOBf6E5offx4D7A39QVe/stbCeVNUtSfZPsrMDirdyFc0sWMPUlv4lyatpZmhNdvONuWv4I0n2BP6Mpou8aLr7xuoimmcwMzh1puss7etf7KOohRhzN98zgd8EHgS8naav+o+q6r29FtazJBuAw6tq1OOBZktySVUdnORpwFOAk2ianh/Qc2m9SfIOmgHn64Afz5wf8lowSyHJ+4EHAJ9ky9BwQm9FDUCSc+c4XVU1xqURtpLkDsAuVXV937Xothtty1RV/UOSi4DH0aTepxogAPiOz2FOM/9Wngy8t6qunzWzb4y+2n6sYvP6MGrC5bp57xqf51XVVZMnkgy2pWGptBNbDqD9GZOEqnpHr0X1LMk64N3Ah5bLIsmja5ma1Se7lSH3yS6FJG8A7g78I1u+qx7rInLArYOKn0rTzXcIzRTvj1TVQ3stTIOU5I7AflV1Zd+1DEWSi6vqQbPOXVRVo13QNMkZwD2BS9hyssLYWzEfTdNz9GTgQuBMmp+3/9VrYdsxxjD1NTb3ye4HfL99vSfwzao6sMfyepfkrXOcrqp67pIXMzBtEL++HS+0K7BHVX2777r6kuTDbB7TMON6YD3wpiH/4FtMSQ4HXgfsXFUHJjkYOGWss/mS3IdmHaVT2XLV/D2AF1fVr8z5B0cgyRXAGnfhmFs7rvmxwPOBw4Y8dnd03XwzYSnJ3wEfrKqz2+Mn0bQ8jFpV/U7fNQzYfYADkkz+uxlzc/xVwGqa5nho3kneANyLZm2yse5F9wqa1stPAVTVJSPvzro3zTjDPdlyG5UbaH5JjtmlND0B/9F3IUPTtu4ezpZjmwdrdC1TM5J8paruN9+5sUjyv6vq1FkLMd7KZmeb42dLcuHsddlmziW5bKwtDkk+X1UPm9xM3S2ZIMnDq+r8vusYknZQ/sE0C3W6kGkryVk0b0g+BrwH+HRVDXq2/ehapiZ8K8kf0WziC80aQt/qsZ6+zQw6X99rFcO1FpvjZ7tTkv2q6psASfaj2QgattwKYmwuS/JbwA5JDgJOAD7Xc01D8LR24U6XF9nsFX0XMFB/DxxTVctmy64xt0zdFXg5MLNx4nnAK8c+AF1zS/Je4ISqsjm+leS/AX9LM6MvwIHA79N0bz2/qv6yv+r6046neynNLgIA5wB/MtYxZDNcXmRuSe4GzLTwfqGq3LuQrWc5AoOe5TjaMDWj3Y26qupHfdfSp20MJr6Vzc42x8+lXRvnPu3hlZOBIckT3IpIM2a6fpO8GXhfVX0syZfGHKaS/HeaBTs/RfOG5FE0g/Lf12ddfVuOwypGG6aS3I9m8PDMUgnfBY6tqkv7q6o/7VTUbRrz/lmw7ecz9ueyPXNNhR+DJJ8AfqOqftAe3wU4s6qe2G9l/XJ5ka0l+RLwhJnWqHYnjn8ec8CE5TnLccxjpt4EnFRV5wIkeQxwOnBon0X1ZTIUuEbO1qrq00n2Bw6qqn9uu3J26LuugRvrqqZ7zQQpuHXfz5/vs6AhqKqT222ZZpYX+TFwZN919WzVrG6962gWwR27ZTfLccxhareZIAVQVZ9KslufBQ3B5Bo5wOjXyJmR5PnAcTQtmfcE9qYZL/S4PusauGXzrnLKfjZrYP7+jPdZzOz3Ofvc5OGYFwT+WJJz2HJ5kbN7rGco9gIuT7JshlWMOUxdleSPgTPa42fRrJszdq9g6zVyRr2QaeuFNM/lAoCq+ndbG7QNfwh8Jsmn2TwO5rh+S+rV4du5Vow4TFXVi5McBTyiPXV6VX2wz5oG4hV9F3BbjTlMPRd4Jc0/5AL+pT03djfPse/caN9VT7ixqm6aeS7twp2jfS5JDqEZEHphkjXAYcC/ziyC2/p6L8X1KMkq4M40iww+rD39P6rqu/1V1a+FLgSc5NiqGvTCjIuhqt4PvL/vOoakHVaxrGY5jnYAuuaW5O9pdrs/GTiKZo2cnarqBb0W1rN2rMcPgN8GXkSzBMDlVfXSXgvrQZKXA0+ieTP2CeChwLnAE4BzqupPeyyvd0nWV9XavutYbsY0YSHJZ6rqkUluYMs3ZaF5kzLYbVOWwnKc5TjaMOWMm7nNWiMnNGvkvMo1crIKeB5bPpc3L6fZJtOS5Cs0y0TcAfg2sE9V/bCduHCBK33nNTSzg98D/HjmvGvYbd/kivEat+U4y3HMYWqrf7j+Y95Su8nkblX1w75r0XDM2iZli38zMwsz9ldd/9rN1Gerqhrz/nzzGlPL1IwkZ1TVs+c7Nzazt3Zr38x+acjbvY15zJQzbuaQ5F3AC2gWSrsQ2CPJG6rqz/qtrB9tK8z2FjMdYyvMTUl2raqfAA+eOZnkzsCg989aCtVupq7bbIxLaWyxf2U7FvPB27h3TOaa5fjRHuuZ15jD1Etxxs1c1rRdNs+k+ct7MnARTf/1GD2l/fzC9vPk7M+xhu9fraobAWZtProTcGw/JQ1H21V+Es1abce1+/Pdu6o+0nNpvUlyH5rlRC6Y3G0iyWFV9bH28LO9FNeDJC+hmfV5xyQzLf+h2dPy9N4KG4h2luPTgUe2pwY/y3G03XwASfZi84ybz495xs2MdiPSg4F3AX/dzqoY9ZYPsM1u4dF1S2h+Sd5D8wbkt6vqvm24+txYuz+TnEDzZuQKmp8tJ1bVh9pro/43lOTVVfWSvusYmnY5nv+YGavbjse8W1V9vdfCtmPsK63eAfge8ENgTZJfnef+MXgTzZT23YDz2u5Px0xBkjxi4uBQ/Pejud2zqk4FbgZou0PH2IU14/nAg6vqqcBjgD9OcmJ7bczPBeALbfc4AEn2TPLUPgsaiPey5ZCBW9pzgzXabr4kr6Xph72Mzf/TCjivt6IGoKreCLxx4tQ3kvxaX/UMyPOAt0z84PsBrkumud3UvpMugCT3ZGIV5xFaNdO1V1Vfb7fuel/7Rm3sYerlk91XVfWDdumRf+yxpiHYsapumjlo1/jbuc+C5jPaMEWz4ea9Z8Z+aLMkT6YZGLnLxOlTeipnEKrqIuABM2Gqqq6fvD7WBQc1p5cDHwP2TfIPNKtbP6fXivr1nSQHV9UlAFX1oyRPAd4CDHZ21hKZq3V7zL+XZ2xMckRVrQNIciTNciODNdoxU0k+SrPO1I/mvXlEkvwtsCvwa8CbgWfQrD77vF4LG7ixj/3QlpL8HM14zDDy8ZhJ9gE2VdW357j2iKoazcDz2ZK8haaV+7T21AuBu1bVc3oragDa1tx/AH6hPXUN8Oyq+mp/VW3fmMPU+4EH0Kz2PbmR4gm9FTUASb5cVfef+Hwn4KNV9ai+axsy1yjTpImZSAV8ZugzkdSPJLsBfww8nubvyieAP62qH2/3D35uPEsAABLFSURBVI5E+/uH2Y0eQ+wJGHNz4rr2Q1v6afv5J0l+AbgOuEeP9SwX43xXoq0k+Rvgl9i8Rs7vJXl8Vb1wO39MI9SGppOT7GaA2tp2eo5OBAxTQ1BVb28Hie5XVVf2Xc+AfCTJnsCpNNO7oenu0/aNfSCtNnss8MszWw0leTvNRBdpC+2s4DcDdwL2S/IA4Peq6vf7rWzwBvfzdrRTu5McDlxCM1CUJAcnsaUKXkczS+3ZwPk0oWrUG9cu0GjHfWgrG4D9Jo73bc9Js/0F8ESaHgCq6kuAS/TMb3A9AaMNU8ArgENoBv/RzjRx76ym6fRXaJZH+CtgDfCOXisagCR3S/L37cQFkqxJcuug/Ko6vr/qNDC7A1ck+VSSc4HLabZlWucbNs1WVVfPOnVLL4UsL4NrmRptNx9wc1Vdn2zx/2T0+4oB962qNRPH5ya5vLdqhuNtwFtptiEC+DfgPcDf91WQButlfRegZePqtquvkuxEMxboip5rGowkj6Rp9Li0qj4+cWlwPQFjDlOXJfktYId276wTgM/1XNMQXJzkYVX1eYAkDwXW91zTEOxVVWe1e2pRVZuS+A5SW6mqT2/vepLzq+rhS1WPBu0FwBto9i28Fvg4m/cBHZ0kX6iqQ9rXz6d5Fh8EXp7kQVX1GhhmT8CYw9SLaFoZbqTZh+4c4E96rahHSb5C0w+9E/C5JN9sj/cH/rXP2gbix+3aQTODih8GXL/9PyLNaZf5b9FKl2QH4A1V9cy+axmQnSZeHwc8oao2Jnkd8HngNf2UNb/Rhql2v6yXsrnbZgtJ/qqqXrS0VfXqKX0XMHAn0Sylcc8knwVW0yxoKt1Wgxs8q6VXVbck2T/JzpNbp4zcqiR3oRnPnaraCM0SEkk29Vva9o02TC3AI+a/ZeWoqm/0XcOQVdXFSR4N3Jtm8OOVVXVzz2VJWt6uAj7bTky4dZ2pqnp9fyX16s40S/KEZhzZParqP9rFOwc36HySYUrajnYl67ncKwlV9YElLUgrwaB/KWhJfbX9WEUzC3TUquqAbVz6GfC0JSzlNhvtdjLzca81ASR563YuV1U9d8mK0bKQ5G40A4oBrq2q78y6ft+qunTpK5O0WAxT2+Bea5JuiyQHA39L01VxbXt6H5q17H6/qi7uqzYNS5K/rKr/keTDzDGGrqqO6KEsdTD6br4ku7aD0Wd7w5IXo8FqZ/K9nInNa4FTquq6XgvTkLyNZiuQCyZPtjM/30qzsboEcEb7+XW9VqGpGW3L1OSeSFXlnkjariSfAM4D3tmeeibwmKp6fH9VaUiS/HtVHbSNaxuq6peWuiZJS2PMYeoCmqnt62a685JcWlX37bcyDdFcfzeSfKWq7tdXTRqWJG8E7kmz/dLMFiH7Ar8NfG2ICw2qHxPr+s2pqu6/hOVoCkbdzVdVV8/aTsYVrbUtH09yNHBWe/wMmoVeJQCq6oQkTwKOZGIAOnBaVZ3dX2UaoJl1/WZWO5/p9nsWrkO2LI25Zep9wOuBvwYeSrMn0tqqOrrXwjRISW4AdmPz/o2r2LwuTFXVHr0UJmnZmmuikzPJl6dVfRfQoxfQvCuY2RPpYEa8J5K2r6p2r6pVVbVj+7GqPbe7QUrzSXJ63zVokJLkERMHhzLu38vL1mhbpqTbKsn9gQOY6B530U7NSHLXbV0CvlRV+yxlPRq+JA8G3kKznEaA7wPPdRmN5We0YSrJqTQbG/8U+Bhwf+APquqd2/2DGqUkb6H5O3IZm7v6XLRTt0pyC/ANtlzhvNrjvatq514K0+AluTNAVbl5+jI15jB1SVUdnORpNIMBTwLOqyrXgtFWklxeVWv6rkPDleTfgcdV1TfnuHZ1Ve3bQ1kaoCTPqqp3Jjlprusj3ptv2Rpz3+xMV82Tgff6jkDzOD+JYUrb85fAXbZx7dSlLESDt1v7efdtfGiZGXPL1GuAp9J08x0C7Al8pKoe2mthGqQkjwbWAd8GbqTd1dz1YHRbJXlCVX2i7zokTc9owxTcOmD0+qq6JcmuwB5V9e2+69LwJNlA0xX8FTaPmaKqvtFbUVqWnPquGUl+kWbrsofRjK87n2bs7lW9FqbbbLSLdib57YnXk5fesfTVaBnYWFXr+i5CK0Lmv0Uj8S7gNOBp7fHRwLtp1j7UMjLaMAU8ZOL1LsDjgIsxTGluX0zyLuDDNN18gEsj6HYZb3eAZtu1qs6YOH5nkhf3Vo1ut9GGqap60eRxkj2BM3sqR8N3R5oQ9esT5wowTEm6TSbWJPtokpNpfvcU8JuAWw8tQ6MeMzUpyU7ApVV1775rkbQ8JVkFPKyqPredez5QVU9fwrI0MEm+xuY1yGarqvrFJS5JHY02TCX5MJub21cBa4Czqurk/qrS0CT531V1apK/Yo7umao6oYeyNGBz7bcm3R7O/Fw+RtvNB7xu4vUm4BtVdU1fxWiwrmg/r++1Ci0nn0xyFPCBGuu7VU3LawHD1DIw2pap+SQ5v6oe3ncdGp62K+dOVfXDvmvR8CS5gWZRxlto1rGbWZPMDbF1m9jKuXyMeQX0+ezSdwEajiTvSrJHkt2AS4HLnXWjuVTV7lW1qqp2qqo92mODlG4PWzuWCcPUtvmXWJPWtC1RTwU+ChwIPLvfkjREaTwryR+3x/smOaTvuiQtHsOUtDA7tTM+nwqsq6qbMXBrbn8DPBz4rfb4RzQLM0rblGSuNQ6/vtR16PYZ8wD0+bhKsSa9ieYH25eA85LsDzhmSnN5aFU9KMkXAarq+0l27rsoDUeS2bspBPi1dr1DquqI9rNLaCwTow5TSe5Os8lxARfO2pfPLhzdqqreCLxx5jjJN4Ffmzg+tqre3kdtGpybk+xA23KZZDUT+zlKwD7A5cCb2bze1Frgz/ssSrffaLv5kvwu8AXg6cAzgM8nee7M9aq6tK/aNHzV2DRx6sTeitHQvBH4IPDzSf4U+Azw//VbkgZmLXAR8FLg+qr6FPDTqvp0VX2618p0u4x2aYQkVwKHVtV17fHPAZ9zBXTdHk5h1qQk96HZ7zPAJ6vqinn+iEYoyT7AXwDfAY6oqv16Lkm305i7+a4Dbpg4vqE9J90e43xXoltN7LcG8J/AuyevVdX3lr4qDVm7UPRvJHkyjsFc1kYXppKc1L7cAFyQ5EM0vwiPBL7cW2Fa7pywoIvYPP5lP+D77es9gW/SLKchbaWq/gn4p77r0O03xjFTu7cfXwX+kc0tCh8CvtZXUVp+kvzOxOFneytEg1BVB7Yb1P4zcHhV7VVVPwc8Bfh4v9VJWkyjHTMldZXkm45x0GxJvlJV95vvnKSVY3TdfDOSnMsc41yq6rE9lKOBSrKtrt8Ad1vKWrRsfCvJHwHvbI+fCXyrx3okLbLRhingf0283gU4Cti0jXs1XncDnkgz/mVSgM8tfTlaBo4BXk6zPALAee05SSvUaMNUVV0069Rnk3yhl2I0ZB8B7lRVl8y+kORTS1+Ohq6dtXdikt2bw/pR3zVJWlyjHTM1axrzKuDBwBtdZ0pSF0nuB7wDmPkZ813gWBcCllau0bZMseU05k00M/me12tFklaCNwEnVdW5AEkeA5wOHNpnUZIWz2jDVFW55oukxbDbTJACqKpPJdmtz4IkLa7RhimAJIcCBzDxHKrqHb0VJGkluCrJHwNntMfPAq7qsR5Ji2zMY6bOAO4JXALc0p6uqjqhv6okLXdJ7gK8EngkzVCCfwFeWVWzZ4RKWiHGHKauANbUWB+AJEmaijFuJzPjUuDufRchaWVJ8okke04c3yXJOX3WJGlxjW7MVJIP0zS97w5c3q4tdePM9ao6oq/aJK0Ie1XVD2YOqur7SX6+z4IkLa7RhSngdX0XIGlF+1mS/arqmwBJ9meOraskrRyjC1NV9emF3Jfk/Kp6+GLXI2nFeSnwmSSfplnH7lHAcf2WJGkxjXYA+nySfLGqHth3HZKWnyR7AQ9rDz9fVd/tsx5Ji2t0LVO3gSlT0u11B+B7ND9j1yShqs7ruSZJi8QwJUlTlOS1wG8ClwE/a08XYJiSVqjRhakkd6iqG+e/kyx6MZJWoqcC917gzxlJK8AY15k6H25dAX17nr0EtUhaea4Cduq7CElLZ3QtU8DOSX4LODTJ02dfrKoPtJ8vXfLKJK0EPwEuSfJJtlzDzq2qpBVqjGHqBcAzgT2Bw2ddK+ADS16RpJVkXfshaSRGuzRCkuOr6q9nnVvoeCpJ2qYkdwT2q6or+65F0uIb45ipGc+d49z5S16FpBUlyeHAJcDH2uODk9hSJa1go+vmS3J3YG/gjkkeyOZZe3sAu/ZWmKSV4hXAIcCnAKrqkiS/2GdBkhbX6MIU8ETgOcA+wJ+zOUz9EPjDnmqStHLcXFXXJ1usrvKzbd0safkbXZiqqrcDb09yVFW9f1v3JTm2vVeSbovL2hnDOyQ5CDgB+FzPNUlaRKMdgD6fJBdX1YP6rkPS8pJkV5rNjn+9PXUO8CdV9V/9VSVpMRmmtsGNjiUthiR/VVUv6rsOSdMz5tl88zFlSloMj+i7AEnTZZjaNvfmkyRJ8xpdmEry0CR7tK/vmOSVST6c5LVJ7jxx62d7KlGSJC0jowtTwFto9s4CeANwZ+C17bm3ztxUVccvfWmSRsBWb2mFGd3SCMCqqtrUvl47MWPvM0ku6asoSStLkl2r6idzXHrDkhcjaVGNsWXq0iS/077+UpK1AEnuBdzcX1mSVoIkhya5HPjX9vgBSf5m5npVva2v2iQtjtEtjdCOi3oD8Cjgu8CDgKvbjxOq6ks9lidpmUtyAfAMYN3M8ipJLq2q+/ZbmaTFMrpuvqq6HnhOOwj9QJpncE1VfaffyiStFFV19aztZG7pqxZJi290YWpGVf0QsBVK0rRdneRQoJLsBJwIXNFzTZIW0ei6+SRpMSXZi2YoweNpZu59HDixqq7rtTBJi8YwJUmS1MEYZ/NJ0qJJcmqSPZLslOSTSTYmeVbfdUlaPIYpSZquX2/HZD4F+DrwS8CLe61I0qIyTEnSdM1M7Hky8N52BrGkFWy0s/kkaZF8JMm/Aj8F/p8kq4H/6rkmSYvIAeiSNGVJ7gpcX1W3JNkV2KOqvt13XZIWhy1TkjRFSX574vXkpXcsfTWSloJhSpKm6yETr3cBHgdcjGFKWrHs5pOkRZRkT+DMqjqs71okLQ5n80nS4voxzT6gklYou/kkaYqSfBiYafJfBawBzuqvIkmLzW4+SZqiJI+eONwEfKOqrumrHkmLzzAlSUsoyflV9fC+65A0PY6ZkqSltUvfBUiaLsOUJC0tuwOkFcYwJUmS1IFhSpKWVua/RdJy4tIIkjRlSe4OHELTpXfhrH35nt1PVZIWiy1TkjRFSX4X+ALwdOAZwOeTPHfmelVd2ldtkhaHSyNI0hQluRI4tKqua49/DvhcVd2738okLRZbpiRpuq4Dbpg4vqE9J2mFcsyUJE1BkpPalxuAC5J8iGbM1JHAl3srTNKiM0xJ0nTs3n7+avsx40M91CJpCTlmSpIkqQNbpiRpipKcyxyrnFfVY3soR9ISMExJ0nT9r4nXuwBHAZt6qkXSErCbT5IWWZIvVNUhfdchaXHYMiVJU5TkrhOHq4AHA3fuqRxJS8AwJUnTdRHNmKnQdO99DXherxVJWlR280mSJHVgy5QkTVmSQ4EDmPgZW1Xv6K0gSYvKMCVJU5TkDOCewCXALe3pAgxT0gplN58kTVGSK4A15Q9XaTTc6FiSputS4O59FyFp6djNJ0lTkOTDNN15uwOXJ/kCcOPM9ao6oq/aJC0uw5QkTcfr+i5AUj8cMyVJSyjJ+VX18L7rkDQ9jpmSpKW1S98FSJouw5QkLS27A6QVxjAlSZLUgWFKkqYgyR0WeuuiFiJpyRmmJGk6zodbV0DfnmcvQS2SlpBLI0jSdOyc5LeAQ5M8ffbFqvpA+/nSJa9M0qIyTEnSdLwAeCawJ3D4rGsFfGDJK5K0JFxnSpKmKMnxVfXXs87doapu3NafkbS8OWZKkqbruXOcO3/Jq5C0ZOzmk6QpSHJ3YG/gjkkeyOZZe3sAu/ZWmKRFZ5iSpOl4IvAcYB/gz9kcpn4I/GFPNUlaAo6ZkqQpSnJUVb1/O9ePraq3L2VNkhaXYUqSllCSi6vqQX3XIWl6HIAuSUvLFdClFcYwJUlLy+4AaYUxTEnS0rJlSlphDFOSNAVJTkiy7wJu/eyiFyNpSTkAXZKmIMn1wI+BrwLvBt5bVRv7rUrSUrBlSpKm4yqaNaZeBTwYuDzJx5Icm2T3fkuTtJhsmZKkKZi95EGSnYAnAccAj6+q1b0VJ2lRGaYkaQqSfLGqHriNa7tW1U+WuiZJS8MwJUlTkOReVfVvfdchaekZpiRJkjpwALokSVIHhilJkqQODFOSJEkdGKYkSZI6+L/GhNDUrzBuqAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize = (10, 7));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Rg55IVqmvZM"
      },
      "source": [
        "## Uploading our model training logs to TensorBoard.dev\n",
        "We can further inspect our model's performance using TensorBoard.dev: https://tensorboard.dev/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb9eEvFmmEPi",
        "outputId": "404bdbdb-d33a-4767-9af8-73d925974c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "./model_logs/\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) NO\n"
          ]
        }
      ],
      "source": [
        "# Load model results on TensorBoard.dev\n",
        "!tensorboard dev upload --logdir ./model_logs/ \\\n",
        "  --name \"NLP_7_models\" \\\n",
        "  --description \"Comparing 7 types of models on Twitter disaster dataset\" \\\n",
        "  --one_shot # exit the uploader once uploading is finished"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3WTJM4xx8MX"
      },
      "source": [
        "Now I've ran the cell above, my modelling experiments are visible on TensorBoard.dev: https://tensorboard.dev/experiment/hNc6v5eLQryiJlKG2k525A/\n",
        "\n",
        "**Resource:** TensorBoard is great for quickly tracking experiments but for larger scale experiments and a whole buch more tracking options, check out Weights & Biases: https://wandb.ai/site"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpTM1ABOQYGg"
      },
      "outputs": [],
      "source": [
        "# #See the previous TensorBoard Dev experiments you've run...\n",
        "# !tensorboard dev list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkFAVwi5IRMb"
      },
      "outputs": [],
      "source": [
        "# # If you need to delete an experiment from TensorBoard, you can run the following:\n",
        "# !tensorboard dev delete --experiment_id #id here#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VE0gKp7sbdE"
      },
      "source": [
        "## Saving and loading a trained model\n",
        "\n",
        "There are two main formats to save a model to in TensorFlow:\n",
        "1. The HDF5 format\n",
        "2. The `SavedModel` format (this is the default when using TensorFlow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BogQU7lRw_3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "369cb339-b5c7-4a53-938b-194be2983566"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.0524934383202,\n",
              " 'precision': 0.8097952566853514,\n",
              " 'recall': 0.800524934383202,\n",
              " 'f1': 0.7966840570849284}"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "# Checking our model_6 results\n",
        "model_6_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScFaoN_ds7bi"
      },
      "outputs": [],
      "source": [
        "# Save TF Hub Sentence Encoder model to HDF5 format\n",
        "model_6.save(\"model_6.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmSWF0F2u6Cu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0EYCqntuffz"
      },
      "outputs": [],
      "source": [
        "# Load model with custom Hub Layer (required HDF5 format)\n",
        "import tensorflow_hub as hub\n",
        "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n",
        "                                            custom_objects ={\"KerasLayer\": hub.KerasLayer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElVC9itEjfKt",
        "outputId": "80cdd105-d01f-4391-ac04-ce56a63fa366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 11ms/step - loss: 0.4445 - accuracy: 0.8005\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4444540739059448, 0.8005249500274658]"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "# How does our loaded model perform?\n",
        "loaded_model_6.evaluate(val_sentences, val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjEV-2moj0gi"
      },
      "source": [
        "Our model_6 saved and loaded correctly using '.h5'.\n",
        "\n",
        "Now let's save to the `SavedModel` format... (see more on this here:)\n",
        "https://www.tensorflow.org/tutorials/keras/save_and_load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xHlPgEvj35a",
        "outputId": "1bfd638a-0bd6-4eb9-9190-052cf5968792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        }
      ],
      "source": [
        "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
        "model_6.save(\"model_6_SavedModel_Format\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNFCl6xHnNy9"
      },
      "outputs": [],
      "source": [
        "# Load in a model from the SavedModel format\n",
        "load_mode_6_SavedModel_format = tf.keras.models.load_model(\"model_6_SavedModel_Format\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI4Wd70dnsgK",
        "outputId": "869c5729-591a-411f-b28d-d51e5bf1b456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 10ms/step - loss: 0.4445 - accuracy: 0.8005\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4444540739059448, 0.8005249500274658]"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "# Evaluate model in SavedModel format\n",
        "load_mode_6_SavedModel_format.evaluate(val_sentences, val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcLskXZs6SYt"
      },
      "source": [
        "## Finding the most wrong examples\n",
        "\n",
        "* If our best model still isn't perfect, what examples is it getting wrong?\n",
        "\n",
        "* And of these wrong examples which ones is it getting *most* wrong (those will prediction probabilities closest to the opposite class)\n",
        "\n",
        "For example if a sample should have a label of 0 but our model predicts a prediction probability of 0.999 (really close to 1) and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrkNE8eE8zLb",
        "outputId": "ff03d095-cbf5-4635-c7c9-67775a1640d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-02 12:03:16--  https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 108.177.97.128, 108.177.125.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 960779165 (916M) [application/zip]\n",
            "Saving to: ‘08_model_6_USE_feature_extractor.zip’\n",
            "\n",
            "08_model_6_USE_feat 100%[===================>] 916.27M   111MB/s    in 9.1s    \n",
            "\n",
            "2022-10-02 12:03:25 (101 MB/s) - ‘08_model_6_USE_feature_extractor.zip’ saved [960779165/960779165]\n",
            "\n",
            "Archive:  08_model_6_USE_feature_extractor.zip\n",
            "   creating: 08_model_6_USE_feature_extractor/\n",
            "   creating: 08_model_6_USE_feature_extractor/assets/\n",
            "   creating: 08_model_6_USE_feature_extractor/variables/\n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.data-00000-of-00001  \n",
            "  inflating: 08_model_6_USE_feature_extractor/variables/variables.index  \n",
            "  inflating: 08_model_6_USE_feature_extractor/saved_model.pb  \n"
          ]
        }
      ],
      "source": [
        "# Download a pretrained model from Google storage\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\n",
        "!unzip 08_model_6_USE_feature_extractor.zip # then add file from address end to unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ron3d8G-Ktr",
        "outputId": "5190199f-6fbe-4094-dc9a-687d56bdf4b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 11ms/step - loss: 0.4272 - accuracy: 0.8163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42723122239112854, 0.8162729740142822]"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "# Import previously trained model from Google Storage\n",
        "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
        "model_6_pretrained.evaluate(val_sentences, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfrOJu21-sso",
        "outputId": "219a9e16-f73f-44ae-95a0-a84eee1372e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "# Make predictions with the loaded model from GS\n",
        "model_6_pretrained_pred_probs = model_6_pretrained.predict(val_sentences)\n",
        "model_6_pretrained_preds = tf.squeeze(tf.round(model_6_pretrained_pred_probs))\n",
        "model_6_pretrained_preds[:10] # they should be in label format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QgM9ur4aoxzb",
        "outputId": "d4b9d673-6310-4dad-8af1-3047347d61c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  target  pred  pred_prob\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.159757\n",
              "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.747162\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988749\n",
              "3  @camilacabello97 Internally and externally scr...       1   0.0   0.196229\n",
              "4  Radiation emergency #preparedness starts with ...       1   1.0   0.707808"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-baeb41c0-f713-4642-9308-ffe004900b2b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.159757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.747162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.988749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.707808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-baeb41c0-f713-4642-9308-ffe004900b2b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-baeb41c0-f713-4642-9308-ffe004900b2b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-baeb41c0-f713-4642-9308-ffe004900b2b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "# Create a DataFrame with validation sentences, validation labels and best performing model prediction labels + probabilities\n",
        "val_df = pd.DataFrame({\"text\": val_sentences,\n",
        "                       \"target\": val_labels,\n",
        "                       \"pred\": model_6_pretrained_preds,\n",
        "                       \"pred_prob\": tf.squeeze(model_6_pretrained_pred_probs)}) # squeeze our pred probs to 1D\n",
        "val_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "WvPqKm0sBh9w",
        "outputId": "50714d63-61bf-41db-81e8-1197a141a511"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
              "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
              "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
              "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
              "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
              "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
              "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
              "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
              "119  @freefromwolves GodsLove &amp; #thankU brother...       0   1.0   \n",
              "344  Air Group is here to the rescue! We have 24/7 ...       0   1.0   \n",
              "\n",
              "     pred_prob  \n",
              "31    0.910196  \n",
              "759   0.876982  \n",
              "628   0.852300  \n",
              "209   0.835454  \n",
              "251   0.827213  \n",
              "393   0.814816  \n",
              "109   0.810840  \n",
              "49    0.803122  \n",
              "119   0.766901  \n",
              "344   0.766625  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1807e4ed-d0f2-4219-bcc8-7ce5fc8bffca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>FedEx will no longer transport bioterror patho...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.876982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.852300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.835454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.827213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.814816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.810840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.803122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>@freefromwolves GodsLove &amp;amp; #thankU brother...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>Air Group is here to the rescue! We have 24/7 ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1807e4ed-d0f2-4219-bcc8-7ce5fc8bffca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1807e4ed-d0f2-4219-bcc8-7ce5fc8bffca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1807e4ed-d0f2-4219-bcc8-7ce5fc8bffca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "# Find the wrong predictions and sort by prediction probabilities\n",
        "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending = False)\n",
        "most_wrong[:10] # False positives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OkrJwVpFCJap",
        "outputId": "a412ad64-18c2-4ec9-b0f1-eee97532de01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  target  pred  \\\n",
              "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
              "233                    I get to smoke my shit in peace       1   0.0   \n",
              "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
              "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   \n",
              "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
              "\n",
              "     pred_prob  \n",
              "411   0.043919  \n",
              "233   0.042087  \n",
              "38    0.038998  \n",
              "244   0.038949  \n",
              "23    0.037186  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de759e44-8f8f-4ea3-bf5e-37c142730961\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>pred</th>\n",
              "      <th>pred_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.043919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>I get to smoke my shit in peace</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Why are you deluged with low self-image? Take ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.037186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de759e44-8f8f-4ea3-bf5e-37c142730961')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de759e44-8f8f-4ea3-bf5e-37c142730961 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de759e44-8f8f-4ea3-bf5e-37c142730961');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "most_wrong.tail() # and these are False Negatives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TCzCxHaFBOC"
      },
      "source": [
        "Let's remind ourselves of the target labels...\n",
        "* `0` = not a disaster\n",
        "* `1` = disaster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrbaUAjnGnqS",
        "outputId": "22bfe0f6-7ae7-4d52-819e-0a122819e18e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1.0, Prob: 0.9101957678794861\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8769821524620056\n",
            "Text:\n",
            "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8523000478744507\n",
            "Text:\n",
            "@noah_anyname That's where the concentration camps and mass murder come in. \n",
            " \n",
            "EVERY. FUCKING. TIME.\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8354544043540955\n",
            "Text:\n",
            "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8272132277488708\n",
            "Text:\n",
            "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.814815878868103\n",
            "Text:\n",
            "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.8108396530151367\n",
            "Text:\n",
            "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.80312180519104\n",
            "Text:\n",
            "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.7669008374214172\n",
            "Text:\n",
            "@freefromwolves GodsLove &amp; #thankU brother Danny for RT of NEW VIDEO http://t.co/cybKsXHF7d The Coming Apocalyptic US Earthquake &amp; Tsunami\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 0, Pred: 1.0, Prob: 0.766625165939331\n",
            "Text:\n",
            "Air Group is here to the rescue! We have 24/7 Emergency Service! Learn more about it here - http://t.co/9lyx7zMtHE http://t.co/5PbC96rTMJ\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check the false positives (model predicted 1 where it should've been 0)\n",
        "for row in most_wrong[:10].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"-----\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JURHjuyHHzCr",
        "outputId": "4defc1da-4dbd-42a8-e684-c50303c78e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1, Pred: 0.0, Prob: 0.06730346381664276\n",
            "Text:\n",
            "@DavidVonderhaar At least you were sincere ??\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.055075809359550476\n",
            "Text:\n",
            "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.054603397846221924\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.05459698289632797\n",
            "Text:\n",
            "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04963727295398712\n",
            "Text:\n",
            "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.04391850158572197\n",
            "Text:\n",
            "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.042086850851774216\n",
            "Text:\n",
            "I get to smoke my shit in peace\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03899792954325676\n",
            "Text:\n",
            "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.03894945606589317\n",
            "Text:\n",
            "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0.0, Prob: 0.037185799330472946\n",
            "Text:\n",
            "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check the false negatives (model predicted 0 where it should've been 0)\n",
        "for row in most_wrong[-10:].itertuples():\n",
        "  _, text, target, pred, pred_prob = row\n",
        "  print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFTRjdwvJdfq",
        "outputId": "729b8c10-eb9b-4b8c-c3e7-85323338fbfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 0, Prob: 0.2628400921821594\n",
            "Text\n",
            "|LIVE NOW| Princes of the Apocalypse:  D&amp;D Encounters #meerkat http://t.co/oY9ES9FVlt\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 1, Prob: 0.6388808488845825\n",
            "Text\n",
            "12000 Nigerian refugees repatriated from Cameroon http://t.co/LeLYa0vDOg read /////\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.3403383493423462\n",
            "Text\n",
            "??Water fight??\n",
            "Penn park 6pm \n",
            "      BYOW\n",
            "(Bring Your Own Weapons)\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 1, Prob: 0.9676203727722168\n",
            "Text\n",
            "Madhya Pradesh Train Derailment: Village Youth Saved Many Lives\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.022144079208374023\n",
            "Text\n",
            "Guess who's got a hilarious new piece on @RazedOnIt? @honeystaysuper! 51 Things You Should Never Say to a Mother Ever http://t.co/ikRHIb9x0a\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 1, Prob: 0.9439738988876343\n",
            "Text\n",
            "Middle East ÛÏHeat DomeÛ Causes Crippling Heat Wave in Israel http://t.co/41Lcb9aepR\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 1, Prob: 0.7452530264854431\n",
            "Text\n",
            "forestservice : RT dhsscitech: #Firefighters run into burning buildingsÛÓwe work on #tech tÛ_ http://t.co/KybQcSvrZa) http://t.co/Ih49kyMsMp\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.23718850314617157\n",
            "Text\n",
            "Black Eye 9: A space battle occurred at Star O784 involving 2 fleets totaling 3936 ships with 5 destroyed\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 0, Prob: 0.1905638873577118\n",
            "Text\n",
            "Unlike the Donaldson dive into the stands no young boys were flattened in the Kyle Parker catch.\n",
            "\n",
            "-----\n",
            "\n",
            "Pred: 1, Prob: 0.9042808413505554\n",
            "Text\n",
            "It doesn't get any closer. Heavy rain just barely missed @TontitownGrape festival but lightning TOO CLOSE #TGF2015 http://t.co/d9PQIXaTX6\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Making predictions on the test dataset and visualizing them\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "test_samples = random.sample(test_sentences, 10)\n",
        "for test_sample in test_samples:\n",
        "  pred_prob = tf.squeeze(model_6_pretrained.predict([test_sample])) # our model expects a list as input\n",
        "  pred = tf.round(pred_prob)\n",
        "  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "  print(f\"Text\\n{test_sample}\\n\")\n",
        "  print(\"-----\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your challenge... predicting on tweets from the wild\n",
        "\n",
        "Go to your favourite Twitter account and copu one of their latest Tweets.\n",
        "\n",
        "Then pass that Tweet through out trained model.\n",
        "\n",
        "It that Tweet a disaster or not disaster (according to the model)? Is the model right or wrong?"
      ],
      "metadata": {
        "id": "5zIIyFo1qoXa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e80c37-841a-4902-f0bd-968c4ef216f5",
        "id": "Qk8_P7HbsVUb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 342,    1,    1,    6,  122, 2744,    1,   17,    2, 1666,    6,\n",
              "           1,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"Released Ukrainian prisoner of war reveals torment at the hands of Russians\"\n",
        "text_vectorizer([sample_sentence])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb527284-876a-4279-8a5a-ebb004afa17d",
        "id": "Se6Klc72rrl6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1, Prob: 0.8949506878852844\n",
            "Text\n",
            "Released Ukrainian prisoner of war reveals torment at the hands of Russians\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Making predictions on the test dataset and visualizing them\n",
        "\n",
        "pred_prob = tf.squeeze(model_6_pretrained.predict([sample_sentence])) # our model expects a list as input\n",
        "pred = tf.round(pred_prob)\n",
        "print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
        "print(f\"Text\\n{sample_sentence}\\n\")\n",
        "print(\"-----\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A disaster was correctly predicted by our loaded pretrained model_6 "
      ],
      "metadata": {
        "id": "_o_xcpUYvH72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The speed/score tradeoff"
      ],
      "metadata": {
        "id": "gp91wHN1vqGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFNuHytqsg1J",
        "outputId": "c9c623cc-87b3-40d4-bbbb-76b562854546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 80.0524934383202,\n",
              " 'precision': 0.8097952566853514,\n",
              " 'recall': 0.800524934383202,\n",
              " 'f1': 0.7966840570849284}"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LUI5RDEvOUJ",
        "outputId": "c1452886-1ad8-4915-cd08-79e7a7da1871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make a funciton to measure the time of prediciton\n",
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples) # make predictions\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time-start_time # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(samples)\n",
        "  return total_time, time_per_pred"
      ],
      "metadata": {
        "id": "3OPPmO9Cvv5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate TF Hub Sentence Encoder time per pred\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model = model_6_pretrained,\n",
        "                                                            samples = val_sentences)\n",
        "model_6_total_pred_time,model_6_time_per_pred"
      ],
      "metadata": {
        "id": "QzPbkOeR43Nn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7853e52a-c498-48a7-8a70-d6a579ec6874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.28642695500002446, 0.0003758883923884835)"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pretty quick!"
      ],
      "metadata": {
        "id": "v0-dQkbzh4zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate our baseline model times per pred\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "baseline_total_pred_time, baseline_time_per_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0aRFMQ6fkc4",
        "outputId": "ced62a8b-6c5d-4afd-8d0a-90c8652952c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.01902775999997175, 2.497081364825689e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the results of our pretrained model 6\n",
        "model_6_pretrained_results = calculate_results(y_true = val_labels,\n",
        "                                               y_pred = model_6_pretrained_preds)\n",
        "model_6_pretrained_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVR8gw0IiSK5",
        "outputId": "3686bd5a-c1a3-4579-ceb1-1ba591a84dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'precision': 0.818446310697231,\n",
              " 'recall': 0.8162729658792651,\n",
              " 'f1': 0.8148082644367335}"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize = (10,7))\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_pretrained_results[\"f1\"], label = \"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-score\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "WqU4ZKHcj_RJ",
        "outputId": "ec56c229-3938-485c-f59d-6f0d9e920c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: is a 3% performance boost worth a x10 fold increase in making a prediction?\n",
        "\n",
        "The ideal position for speed and performance is the top left corner on our plot"
      ],
      "metadata": {
        "id": "cs3wR1T-l6xL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oHNYRqnUk4UY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNXe7gBLmAZoqZQCszK1YH7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}